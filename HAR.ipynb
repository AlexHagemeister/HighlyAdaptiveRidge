{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore me - go to My_HAL_sims.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the Python implementation of the HAL algorithm.\n",
    "\n",
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "from sklearn.linear_model import LassoCV\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main HAL implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def quantize_col(x, k):\n",
    "    \"\"\"\n",
    "    Quantizes the values in array x into k equally spaced bins.\n",
    "\n",
    "    Parameters:\n",
    "    x (ndarray): Input array to be quantized.\n",
    "    k (int): Number of bins to quantize the values into.\n",
    "\n",
    "    Returns:\n",
    "    ndarray: Quantized array with values replaced by their corresponding bin values.\n",
    "    \"\"\"\n",
    "    if k == 0:\n",
    "        return np.full_like(x, np.min(x))\n",
    "    quantiles = np.quantile(x, np.arange(0, 1, 1/k))\n",
    "    indices = np.searchsorted(quantiles, x, side='right') - 1\n",
    "    return quantiles[indices]\n",
    "\n",
    "def quantize(X, k):\n",
    "    \"\"\"\n",
    "    Quantizes the input matrix X by reducing the number of unique values in each column to k.\n",
    "\n",
    "    Parameters:\n",
    "    X (numpy.ndarray): The input matrix of shape (n_samples, n_features).\n",
    "    k (int): The desired number of unique values in each column after quantization.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The quantized matrix of shape (n_samples, n_features).\n",
    "    \"\"\"\n",
    "    if k >= X.shape[0]:\n",
    "        return X\n",
    "    return np.stack([quantize_col(x, k) for x in X.T]).T\n",
    "\n",
    "class HAL:\n",
    "    \"\"\"\n",
    "    HAL (Hierarchical Adaptive Lasso) class for feature selection and prediction.\n",
    "\n",
    "    Parameters:\n",
    "    - bin_depths (dict): A dictionary specifying the bin depths for each number of bins. \n",
    "                         The keys represent the number of bins, and the values are lists of depths.\n",
    "                         If None, the default bin depths are {np.inf: []}.\n",
    "    - sparse_cutoff (float): The cutoff value for sparsity. Default is None.\n",
    "    - filter (bool): Whether to apply feature filtering. Default is False.\n",
    "    - **kwargs: Additional keyword arguments to be passed to the LassoCV class.\n",
    "\n",
    "    Methods:\n",
    "    - fit_val(X, Y): Fit the HAL model on the training data X and target variable Y.\n",
    "    - predict(X): Make predictions using the HAL model on the input data X.\n",
    "    \"\"\"\n",
    "    def __init__(self, bin_depths=None, sparse_cutoff=None, filter=False, **kwargs):\n",
    "        self.lasso = LassoCV(**kwargs)\n",
    "        self.sparse_cutoff = sparse_cutoff\n",
    "        self.filter = filter\n",
    "        self.filter_idx = slice(None)\n",
    "        if bin_depths is None: # {n_bin: (depths)}\n",
    "            self.bin_depths = {np.inf: []}\n",
    "        else:\n",
    "            self.bin_depths = bin_depths\n",
    "\n",
    "    @classmethod\n",
    "    def _basis_products(cls, one_way, max_depth=None, index=0, basis=None, bases=None):\n",
    "        if max_depth is None:\n",
    "            max_depth = len(one_way)\n",
    "        if bases is None:\n",
    "            bases = defaultdict(list)\n",
    "        if basis is None:\n",
    "            basis = np.ones_like(one_way[0], dtype=bool)\n",
    "\n",
    "        if index == len(one_way) or max_depth == 0:\n",
    "            bases[max_depth].append(basis)\n",
    "        else:\n",
    "            cls._basis_products(one_way, max_depth-1, index+1, basis & one_way[index], bases)\n",
    "            cls._basis_products(one_way, max_depth,   index+1, basis,                  bases)\n",
    "        return bases\n",
    "\n",
    "    @classmethod\n",
    "    def _one_way(cls, X, knots):\n",
    "        return np.stack([\n",
    "            np.less_equal.outer(knots[:,j], X[:,j])\n",
    "            for j in range(knots.shape[1])\n",
    "        ])\n",
    "\n",
    "    @classmethod\n",
    "    def bases(cls, X, knots, depths):\n",
    "        if len(depths)==0: # [] represents all depths\n",
    "            depths = range(1, X.shape[1]+1)\n",
    "        bases = cls._basis_products(cls._one_way(X, knots), max(depths))\n",
    "        return np.concatenate(list(chain.from_iterable(\n",
    "            [bases[max(depths)-d] for d in depths]\n",
    "        )))\n",
    "\n",
    "    def multibases(self, X):\n",
    "        return np.concatenate([\n",
    "            self.bases(X, knots, depths)\n",
    "            for (depths, knots) in self.knots.items()\n",
    "        ]).T\n",
    "\n",
    "    def filter_bases(self, H):\n",
    "        if self.sparse_cutoff is None:\n",
    "            self.sparse_cutoff = 1/np.sqrt(H.shape[0])\n",
    "        H, filter_idx = np.unique(H, return_index=True, axis=1)\n",
    "        pct1 = np.mean(H, axis=0)\n",
    "        keep = (self.sparse_cutoff < pct1) & (pct1 < 1-self.sparse_cutoff)\n",
    "        self.filter_idx = filter_idx[keep]\n",
    "        return H[:,keep]\n",
    "\n",
    "    def fit_val(self, X, Y):\n",
    "        self.knots = {\n",
    "            tuple(depths): quantize(X, n_bin)\n",
    "            for (n_bin, depths) in self.bin_depths.items()\n",
    "        }\n",
    "        H = self.multibases(X)\n",
    "        if self.filter:\n",
    "            H = self.filter_bases(H)\n",
    "\n",
    "        self.lasso.fit(H, Y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        H = self.multibases(X)[:,self.filter_idx]\n",
    "        return self.lasso.predict(H)\n",
    "\n",
    "def HAL9001(**kwargs):\n",
    "    \"\"\"\n",
    "    This function creates an instance of the HAL class with predefined bin depths.\n",
    "    \n",
    "    Parameters:\n",
    "    - kwargs: Additional keyword arguments to be passed to the HAL constructor.\n",
    "    \n",
    "    Returns:\n",
    "    - An instance of the HAL class.\n",
    "    \"\"\"\n",
    "    return HAL(bin_depths = {200/2**(d-1):[d] for d in range(1,4)}, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generator functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate simple 2D data\n",
    "\n",
    "def generate_multivariate_data(n=500, d=2):\n",
    "    \"\"\"\n",
    "    Generates data with multivariate inputs and a univariate output based on specified parameters.\n",
    "    \n",
    "    Parameters:\n",
    "    - n: Number of samples.\n",
    "    - d: Dimensionality of the input data (X).\n",
    "    \n",
    "    Returns:\n",
    "    A pandas DataFrame with columns ['X1', 'X2', ..., 'Xd', 'Y'] for d-dimensional X and univariate Y.\n",
    "    \"\"\"\n",
    "    np.random.seed(0)  # For reproducibility\n",
    "    \n",
    "    # Generate independent variables with d dimensions\n",
    "    X = np.random.uniform(-4, 4, size=(n, d))\n",
    "    \n",
    "    # Generate noise\n",
    "    epsilon = np.random.normal(0, 1, size=(n, 1))\n",
    "    \n",
    "    # Generate dependent variable, using magnitude of X vector for d > 1\n",
    "    if d > 1:\n",
    "        # Calculate magnitude of X\n",
    "        X_magnitude = np.linalg.norm(X, axis=1).reshape(-1, 1)\n",
    "        Y = 2 * np.sin(np.pi / 2 * np.abs(X_magnitude)) + epsilon\n",
    "    else:\n",
    "        # Use absolute value of X directly for d = 1\n",
    "        Y = 2 * np.sin(np.pi / 2 * np.abs(X)) + epsilon\n",
    "    \n",
    "    # Creating DataFrame\n",
    "    column_names = ['X' + str(i+1) for i in range(d)] + ['Y']\n",
    "    data = pd.DataFrame(np.hstack((X, Y)), columns=column_names)\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the data with d=2\n",
    "data_2d = generate_multivariate_data(d=2)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "data_2d.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.188975</td>\n",
       "      <td>-1.107711</td>\n",
       "      <td>0.131110</td>\n",
       "      <td>0.479788</td>\n",
       "      <td>2.158754</td>\n",
       "      <td>0.673468</td>\n",
       "      <td>-0.023772</td>\n",
       "      <td>-0.522301</td>\n",
       "      <td>-0.376051</td>\n",
       "      <td>2.385984</td>\n",
       "      <td>65.052001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.304678</td>\n",
       "      <td>0.873407</td>\n",
       "      <td>-0.224040</td>\n",
       "      <td>1.137279</td>\n",
       "      <td>-0.158486</td>\n",
       "      <td>-0.167797</td>\n",
       "      <td>0.329299</td>\n",
       "      <td>0.095985</td>\n",
       "      <td>0.882807</td>\n",
       "      <td>1.480140</td>\n",
       "      <td>227.463721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.606542</td>\n",
       "      <td>-0.735028</td>\n",
       "      <td>-0.528557</td>\n",
       "      <td>-0.071976</td>\n",
       "      <td>0.379535</td>\n",
       "      <td>-0.038572</td>\n",
       "      <td>-1.376957</td>\n",
       "      <td>1.863931</td>\n",
       "      <td>-1.431093</td>\n",
       "      <td>1.100499</td>\n",
       "      <td>-207.454736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.799108</td>\n",
       "      <td>-0.557484</td>\n",
       "      <td>-0.790976</td>\n",
       "      <td>-0.832768</td>\n",
       "      <td>0.909953</td>\n",
       "      <td>0.982595</td>\n",
       "      <td>0.172157</td>\n",
       "      <td>-0.927648</td>\n",
       "      <td>0.124563</td>\n",
       "      <td>-0.392564</td>\n",
       "      <td>-63.067181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.588897</td>\n",
       "      <td>-0.328640</td>\n",
       "      <td>1.733899</td>\n",
       "      <td>-0.891965</td>\n",
       "      <td>0.699899</td>\n",
       "      <td>0.481374</td>\n",
       "      <td>3.033027</td>\n",
       "      <td>0.282997</td>\n",
       "      <td>0.449477</td>\n",
       "      <td>-0.306869</td>\n",
       "      <td>227.288541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1        X2        X3        X4        X5        X6        X7  \\\n",
       "0 -1.188975 -1.107711  0.131110  0.479788  2.158754  0.673468 -0.023772   \n",
       "1  0.304678  0.873407 -0.224040  1.137279 -0.158486 -0.167797  0.329299   \n",
       "2  0.606542 -0.735028 -0.528557 -0.071976  0.379535 -0.038572 -1.376957   \n",
       "3 -0.799108 -0.557484 -0.790976 -0.832768  0.909953  0.982595  0.172157   \n",
       "4  0.588897 -0.328640  1.733899 -0.891965  0.699899  0.481374  3.033027   \n",
       "\n",
       "         X8        X9       X10           Y  \n",
       "0 -0.522301 -0.376051  2.385984   65.052001  \n",
       "1  0.095985  0.882807  1.480140  227.463721  \n",
       "2  1.863931 -1.431093  1.100499 -207.454736  \n",
       "3 -0.927648  0.124563 -0.392564  -63.067181  \n",
       "4  0.282997  0.449477 -0.306869  227.288541  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Create feature and target arrays:\n",
    "# X = everything EXCEPT the Y1 colums (features)\n",
    "X = regression_data.drop(\"Y\", axis=1).values\n",
    "# y = the Y1 column (target)\n",
    "y = regression_data[\"Y\"].values\n",
    "\n",
    "## Split the data into training and test sets:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 3196.66\n"
     ]
    }
   ],
   "source": [
    "hal = HAL()\n",
    "\n",
    "# Fit the model to the training data\n",
    "hal.fit_val(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = hal.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Print the mean squared error\n",
    "print(f'Mean Squared Error: {mse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Highly_Adaptive_Ridge-awx9OXbz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
