{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BASIC PLOTTING TEST\n",
    "\n",
    "from data_generators import DataGenerator, SmoothDataGenerator, JumpDataGenerator, SinusoidalDataGenerator\n",
    "from kernel_har import KernelHAR\n",
    "from highly_adaptive_lasso import HAL\n",
    "from highly_adaptive_ridge import HAR\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from run_trials import RunTrials\n",
    "import warnings\n",
    "from train_time_plotter import TrainTimePlotter\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "d = 1\n",
    "\n",
    "# Create a list of sample sizes at regular intervals \n",
    "sample_sizes = np.arange(start=100, stop=1000, step=100)\n",
    "\n",
    "# Number of trials to run for each sample size, dgp, model\n",
    "num_trials = 3\n",
    "\n",
    "# Create a data generator\n",
    "dgp = SmoothDataGenerator()\n",
    "\n",
    "results = RunTrials.run_trials(d, sample_sizes, num_trials, dgp)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-c5440cd1e55b49c2bc2a2bb6399d7ad8.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-c5440cd1e55b49c2bc2a2bb6399d7ad8.vega-embed details,\n",
       "  #altair-viz-c5440cd1e55b49c2bc2a2bb6399d7ad8.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-c5440cd1e55b49c2bc2a2bb6399d7ad8\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-c5440cd1e55b49c2bc2a2bb6399d7ad8\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-c5440cd1e55b49c2bc2a2bb6399d7ad8\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"axis\": {\"grid\": true}, \"legend\": {\"labelFontSize\": 10, \"titleFontSize\": 12}, \"title\": {\"fontSize\": 16}}, \"data\": {\"name\": \"data-38a7f9e7e9f76acf4f54951ec08aaf9d\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"field\": \"Method\", \"legend\": {\"title\": \"Method\"}, \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"Sample Size\", \"type\": \"quantitative\"}, {\"field\": \"Method\", \"type\": \"nominal\"}, {\"field\": \"mean_training_time\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Sample Size\", \"title\": \"Sample Size\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_training_time\", \"title\": \"Mean Training Time (s)\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Training Time vs. Sample Size\\n(d=1, Smooth dgp)\", \"width\": 600, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-38a7f9e7e9f76acf4f54951ec08aaf9d\": [{\"Sample Size\": 100, \"Method\": \"HAR\", \"mean_training_time\": 0.0013620058695475261, \"std_training_time\": 0.0005508689690085745}, {\"Sample Size\": 200, \"Method\": \"HAR\", \"mean_training_time\": 0.0006124178568522135, \"std_training_time\": 8.700459869501859e-05}, {\"Sample Size\": 300, \"Method\": \"HAR\", \"mean_training_time\": 0.0006401538848876953, \"std_training_time\": 9.236589309134673e-05}, {\"Sample Size\": 400, \"Method\": \"HAR\", \"mean_training_time\": 0.0030945936838785806, \"std_training_time\": 0.003958522661533053}, {\"Sample Size\": 500, \"Method\": \"HAR\", \"mean_training_time\": 0.001296679178873698, \"std_training_time\": 0.0006598419431229734}, {\"Sample Size\": 600, \"Method\": \"HAR\", \"mean_training_time\": 0.0013803641001383464, \"std_training_time\": 0.0006602757230929401}, {\"Sample Size\": 700, \"Method\": \"HAR\", \"mean_training_time\": 0.010675589243570963, \"std_training_time\": 0.00448770671581495}, {\"Sample Size\": 800, \"Method\": \"HAR\", \"mean_training_time\": 0.028251489003499348, \"std_training_time\": 0.015579791516393975}, {\"Sample Size\": 900, \"Method\": \"HAR\", \"mean_training_time\": 0.06962354977925618, \"std_training_time\": 0.02881237312118693}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from train_time_plotter import TrainTimePlotter\n",
    "\n",
    "# Plot the training time\n",
    "TrainTimePlotter.plot(df, d, dgp.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 1.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Saved DataFrame to Training_df_files/dataframe_d1_dgp_Smooth.pickle\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1.0\n",
      "Best lambda: 1.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 1.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 1.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 100.0\n",
      "Saved DataFrame to Training_df_files/dataframe_d1_dgp_Jump.pickle\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 10.0\n",
      "Saved DataFrame to Training_df_files/dataframe_d1_dgp_Sinusoidal.pickle\n",
      "Best lambda: 1.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 1.0\n",
      "Best lambda: 1.0\n",
      "Best lambda: 1.0\n",
      "Best lambda: 1.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 0.01\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 1.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 1.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 1.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 10.0\n",
      "Saved DataFrame to Training_df_files/dataframe_d3_dgp_Smooth.pickle\n",
      "Best lambda: 100.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 1.0\n",
      "Best lambda: 1.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 1.0\n",
      "Best lambda: 0.1\n",
      "Best lambda: 100.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 1.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 0.01\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 1.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 0.1\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 0.01\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Saved DataFrame to Training_df_files/dataframe_d3_dgp_Jump.pickle\n",
      "Best lambda: 10.0\n",
      "Best lambda: 1.0\n",
      "Best lambda: 0.01\n",
      "Best lambda: 100.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 1.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 1.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 10.0\n",
      "Saved DataFrame to Training_df_files/dataframe_d3_dgp_Sinusoidal.pickle\n",
      "Best lambda: 1.0\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 0.01\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 0.01\n",
      "Best lambda: 10.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 0.01\n",
      "Best lambda: 10.0\n",
      "Best lambda: 0.01\n",
      "Best lambda: 10.0\n",
      "Best lambda: 0.01\n",
      "Best lambda: 0.01\n",
      "Best lambda: 0.01\n",
      "Best lambda: 10.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 0.01\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 0.1\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 1.0\n",
      "Best lambda: 0.01\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 0.01\n",
      "Best lambda: 100.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 0.01\n",
      "Best lambda: 100.0\n",
      "Saved DataFrame to Training_df_files/dataframe_d5_dgp_Smooth.pickle\n",
      "Best lambda: 100.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 0.01\n",
      "Best lambda: 0.01\n",
      "Best lambda: 0.01\n",
      "Best lambda: 0.01\n",
      "Best lambda: 100.0\n",
      "Best lambda: 0.01\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 0.01\n",
      "Best lambda: 0.01\n",
      "Best lambda: 0.01\n",
      "Best lambda: 10.0\n",
      "Best lambda: 0.01\n",
      "Best lambda: 0.01\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 0.01\n",
      "Best lambda: 0.01\n",
      "Best lambda: 10.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 1.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 0.01\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 0.01\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 1.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 100.0\n",
      "Saved DataFrame to Training_df_files/dataframe_d5_dgp_Jump.pickle\n",
      "Best lambda: 1000.0\n",
      "Best lambda: 0.01\n",
      "Best lambda: 0.01\n",
      "Best lambda: 0.01\n",
      "Best lambda: 100.0\n",
      "Best lambda: 0.01\n",
      "Best lambda: 10.0\n",
      "Best lambda: 0.01\n",
      "Best lambda: 0.01\n",
      "Best lambda: 10.0\n",
      "Best lambda: 0.01\n",
      "Best lambda: 100.0\n",
      "Best lambda: 0.01\n",
      "Best lambda: 0.01\n",
      "Best lambda: 1.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 0.01\n",
      "Best lambda: 100.0\n",
      "Best lambda: 0.01\n",
      "Best lambda: 10.0\n",
      "Best lambda: 0.01\n",
      "Best lambda: 0.01\n",
      "Best lambda: 10.0\n",
      "Best lambda: 1.0\n",
      "Best lambda: 0.01\n",
      "Best lambda: 10.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 0.01\n",
      "Best lambda: 10.0\n",
      "Best lambda: 0.01\n",
      "Best lambda: 10.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 1.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 10.0\n",
      "Best lambda: 100.0\n",
      "Best lambda: 10.0\n",
      "Saved DataFrame to Training_df_files/dataframe_d5_dgp_Sinusoidal.pickle\n"
     ]
    }
   ],
   "source": [
    "## Run trials for all combinations of d sizes, sample sizes, and data generators\n",
    "\n",
    "# IMPORTS REQUIRED FOR TRAINING, PLOTTING, AND SAVING DATAFRAMES\n",
    "import numpy as np\n",
    "from data_generators import DataGenerator, SmoothDataGenerator, JumpDataGenerator, SinusoidalDataGenerator\n",
    "import pandas as pd \n",
    "from run_trials import RunTrials\n",
    "import warnings\n",
    "from train_time_plotter import TrainTimePlotter\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "## Setup: Define the parameters for the experiment\n",
    "\n",
    "ALL_DF_FILE_NAMES = \"Training_df_files/all_file_names.pickle\"\n",
    "\n",
    "d_sizes = [1, 3, 5]     # Dimensionality of the data (same as HAL paper)\n",
    "num_trials = 5          # Number of trials to run for each sample size, dgp, model\n",
    "sample_sizes = np.arange(start=100, stop=1000, step=100) \n",
    "data_generators = [SmoothDataGenerator, JumpDataGenerator, SinusoidalDataGenerator]\n",
    "data_frames = [] # List to store all DataFrames for each combination of d, sample size, and data generator\n",
    "all_plots = [] # List to store all plots (might as well!)\n",
    "all_file_names = [] # List to store all file names for the saved DataFrames\n",
    "\n",
    "# Run trials for all combinations of d sizes, sample sizes, and data generators\n",
    "for d in d_sizes:\n",
    "    for dgp in data_generators:\n",
    "\n",
    "        # Run trials for the current combination of d, sample size, and data generator\n",
    "        results = RunTrials.run_trials(d, sample_sizes, num_trials, dgp)\n",
    "\n",
    "        # Convert results to DataFrame and append to the list of all DataFrames\n",
    "        df = pd.DataFrame(results)\n",
    "        data_frames.append(df)\n",
    "\n",
    "        # Generate a descriptive file name, save to pickle format, and append to the list of all file names\n",
    "        file_name = f\"Training_df_files/dataframe_d{d}_dgp_{dgp.name}.pickle\"\n",
    "        df.to_pickle(file_name)\n",
    "        all_file_names.append(file_name)\n",
    "        print(f\"Saved DataFrame to {file_name}\")\n",
    "\n",
    "        # Append the plot to the list of all plots, and display the plot\n",
    "        plot = TrainTimePlotter.plot(df, d, dgp.name)\n",
    "        all_plots.append(plot)\n",
    "        # display(plot)\n",
    "        \n",
    "# Save the file names to a pickle file\n",
    "with open(ALL_DF_FILE_NAMES, \"wb\") as f:\n",
    "    pickle.dump(all_file_names, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-818ae6b65fb24633a3762399fc6b8cb1.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-818ae6b65fb24633a3762399fc6b8cb1.vega-embed details,\n",
       "  #altair-viz-818ae6b65fb24633a3762399fc6b8cb1.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-818ae6b65fb24633a3762399fc6b8cb1\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-818ae6b65fb24633a3762399fc6b8cb1\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-818ae6b65fb24633a3762399fc6b8cb1\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"vconcat\": [{\"hconcat\": [{\"data\": {\"name\": \"data-cb286184deaf2c89c0cd6771c1ac59e5\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"field\": \"Method\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"Sample Size\", \"type\": \"quantitative\"}, {\"field\": \"Method\", \"type\": \"nominal\"}, {\"field\": \"mean_training_time\", \"type\": \"quantitative\"}, {\"field\": \"std_training_time\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Sample Size\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_training_time\", \"title\": \"Mean Training Time (s), d=1\", \"type\": \"quantitative\"}}, \"height\": 200, \"title\": \"DGP: Smooth\", \"width\": 400}, {\"data\": {\"name\": \"data-1dacc4ec44928ebb120c33d7c8aa239b\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"field\": \"Method\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"Sample Size\", \"type\": \"quantitative\"}, {\"field\": \"Method\", \"type\": \"nominal\"}, {\"field\": \"mean_training_time\", \"type\": \"quantitative\"}, {\"field\": \"std_training_time\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Sample Size\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_training_time\", \"title\": \"Mean Training Time (s), d=1\", \"type\": \"quantitative\"}}, \"height\": 200, \"title\": \"DGP: Jump\", \"width\": 400}, {\"data\": {\"name\": \"data-aa419d3ea4b80fba00ead84438884322\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"field\": \"Method\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"Sample Size\", \"type\": \"quantitative\"}, {\"field\": \"Method\", \"type\": \"nominal\"}, {\"field\": \"mean_training_time\", \"type\": \"quantitative\"}, {\"field\": \"std_training_time\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Sample Size\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_training_time\", \"title\": \"Mean Training Time (s), d=1\", \"type\": \"quantitative\"}}, \"height\": 200, \"title\": \"DGP: Sinusoidal\", \"width\": 400}]}, {\"hconcat\": [{\"data\": {\"name\": \"data-2ab6b26efc991e90e000df889f071971\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"field\": \"Method\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"Sample Size\", \"type\": \"quantitative\"}, {\"field\": \"Method\", \"type\": \"nominal\"}, {\"field\": \"mean_training_time\", \"type\": \"quantitative\"}, {\"field\": \"std_training_time\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Sample Size\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_training_time\", \"title\": \"Mean Training Time (s), d=3\", \"type\": \"quantitative\"}}, \"height\": 200, \"title\": \"DGP: Smooth\", \"width\": 400}, {\"data\": {\"name\": \"data-3ec00f4ff172a4c6ac116c15f1ec0107\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"field\": \"Method\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"Sample Size\", \"type\": \"quantitative\"}, {\"field\": \"Method\", \"type\": \"nominal\"}, {\"field\": \"mean_training_time\", \"type\": \"quantitative\"}, {\"field\": \"std_training_time\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Sample Size\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_training_time\", \"title\": \"Mean Training Time (s), d=3\", \"type\": \"quantitative\"}}, \"height\": 200, \"title\": \"DGP: Jump\", \"width\": 400}, {\"data\": {\"name\": \"data-d57f535b1b14c6613813d02d790ef533\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"field\": \"Method\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"Sample Size\", \"type\": \"quantitative\"}, {\"field\": \"Method\", \"type\": \"nominal\"}, {\"field\": \"mean_training_time\", \"type\": \"quantitative\"}, {\"field\": \"std_training_time\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Sample Size\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_training_time\", \"title\": \"Mean Training Time (s), d=3\", \"type\": \"quantitative\"}}, \"height\": 200, \"title\": \"DGP: Sinusoidal\", \"width\": 400}]}, {\"hconcat\": [{\"data\": {\"name\": \"data-c55f263b7fbf851d00b0d22d7fe143fa\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"field\": \"Method\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"Sample Size\", \"type\": \"quantitative\"}, {\"field\": \"Method\", \"type\": \"nominal\"}, {\"field\": \"mean_training_time\", \"type\": \"quantitative\"}, {\"field\": \"std_training_time\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Sample Size\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_training_time\", \"title\": \"Mean Training Time (s), d=5\", \"type\": \"quantitative\"}}, \"height\": 200, \"title\": \"DGP: Smooth\", \"width\": 400}, {\"data\": {\"name\": \"data-481d649dcf387ee8403bc58bc9f636a0\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"field\": \"Method\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"Sample Size\", \"type\": \"quantitative\"}, {\"field\": \"Method\", \"type\": \"nominal\"}, {\"field\": \"mean_training_time\", \"type\": \"quantitative\"}, {\"field\": \"std_training_time\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Sample Size\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_training_time\", \"title\": \"Mean Training Time (s), d=5\", \"type\": \"quantitative\"}}, \"height\": 200, \"title\": \"DGP: Jump\", \"width\": 400}, {\"data\": {\"name\": \"data-a943bd30eee77ee97e65febcda2a267f\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"field\": \"Method\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"Sample Size\", \"type\": \"quantitative\"}, {\"field\": \"Method\", \"type\": \"nominal\"}, {\"field\": \"mean_training_time\", \"type\": \"quantitative\"}, {\"field\": \"std_training_time\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Sample Size\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_training_time\", \"title\": \"Mean Training Time (s), d=5\", \"type\": \"quantitative\"}}, \"height\": 200, \"title\": \"DGP: Sinusoidal\", \"width\": 400}]}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-cb286184deaf2c89c0cd6771c1ac59e5\": [{\"Sample Size\": 100, \"Method\": \"HAL\", \"mean_training_time\": 0.010038614273071289, \"std_training_time\": 0.0022129217833557055, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 100, \"Method\": \"HAR\", \"mean_training_time\": 0.0005128383636474609, \"std_training_time\": 0.00018788616931467503, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 100, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.006721687316894531, \"std_training_time\": 0.0025223787493210024, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 200, \"Method\": \"HAL\", \"mean_training_time\": 0.03780741691589355, \"std_training_time\": 0.006098779116421307, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 200, \"Method\": \"HAR\", \"mean_training_time\": 0.0006020545959472656, \"std_training_time\": 0.00040604648861744807, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 200, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.05449409484863281, \"std_training_time\": 0.05794890992247323, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 300, \"Method\": \"HAL\", \"mean_training_time\": 0.11341686248779297, \"std_training_time\": 0.020785203150704645, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 300, \"Method\": \"HAR\", \"mean_training_time\": 0.0006775379180908204, \"std_training_time\": 0.000382369864431264, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 300, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.06371083259582519, \"std_training_time\": 0.05103300829218906, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 400, \"Method\": \"HAL\", \"mean_training_time\": 0.122078275680542, \"std_training_time\": 0.02319004415270919, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 400, \"Method\": \"HAR\", \"mean_training_time\": 0.0005202293395996094, \"std_training_time\": 1.6519844247169504e-05, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 400, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.01578049659729004, \"std_training_time\": 0.009886370913857833, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 500, \"Method\": \"HAL\", \"mean_training_time\": 0.23036370277404786, \"std_training_time\": 0.04652403055034102, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 500, \"Method\": \"HAR\", \"mean_training_time\": 0.0006337642669677734, \"std_training_time\": 3.638145649720041e-05, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 500, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.013169193267822265, \"std_training_time\": 0.0030141723472233645, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 600, \"Method\": \"HAL\", \"mean_training_time\": 0.48116536140441896, \"std_training_time\": 0.09780762681092366, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 600, \"Method\": \"HAR\", \"mean_training_time\": 0.0009380340576171875, \"std_training_time\": 0.0004260484839702869, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 600, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.24599013328552247, \"std_training_time\": 0.2275543027073622, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 700, \"Method\": \"HAL\", \"mean_training_time\": 0.7651348114013672, \"std_training_time\": 0.06293994140913757, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 700, \"Method\": \"HAR\", \"mean_training_time\": 0.018092584609985352, \"std_training_time\": 0.005463748807781806, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 700, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.2837815761566162, \"std_training_time\": 0.015233112343174936, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 800, \"Method\": \"HAL\", \"mean_training_time\": 0.8128959655761718, \"std_training_time\": 0.14530181983716142, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 800, \"Method\": \"HAR\", \"mean_training_time\": 0.02296905517578125, \"std_training_time\": 0.004476828438306152, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 800, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.28272209167480467, \"std_training_time\": 0.023836842108024378, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 900, \"Method\": \"HAL\", \"mean_training_time\": 1.2312941074371337, \"std_training_time\": 0.08687341067539286, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 900, \"Method\": \"HAR\", \"mean_training_time\": 0.023232316970825194, \"std_training_time\": 0.012176743260098577, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 900, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.30950160026550294, \"std_training_time\": 0.041008964112122695, \"d\": 1, \"dgp_type\": \"Smooth\"}], \"data-1dacc4ec44928ebb120c33d7c8aa239b\": [{\"Sample Size\": 100, \"Method\": \"HAL\", \"mean_training_time\": 0.008745765686035157, \"std_training_time\": 0.002640141070667469, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 100, \"Method\": \"HAR\", \"mean_training_time\": 0.00034780502319335936, \"std_training_time\": 5.170287059197962e-05, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 100, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.007848405838012695, \"std_training_time\": 0.005093459059123995, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 200, \"Method\": \"HAL\", \"mean_training_time\": 0.03276944160461426, \"std_training_time\": 0.005902940082409864, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 200, \"Method\": \"HAR\", \"mean_training_time\": 0.000674295425415039, \"std_training_time\": 0.000672272677088961, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 200, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.009843158721923827, \"std_training_time\": 0.0028789962305683266, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 300, \"Method\": \"HAL\", \"mean_training_time\": 0.09750833511352539, \"std_training_time\": 0.010785737990793081, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 300, \"Method\": \"HAR\", \"mean_training_time\": 0.0004363059997558594, \"std_training_time\": 5.934180481268716e-06, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 300, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.016643524169921875, \"std_training_time\": 0.01620871188257094, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 400, \"Method\": \"HAL\", \"mean_training_time\": 0.12084083557128907, \"std_training_time\": 0.024228770116428166, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 400, \"Method\": \"HAR\", \"mean_training_time\": 0.0005201816558837891, \"std_training_time\": 2.3047444461991725e-05, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 400, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.014380836486816406, \"std_training_time\": 0.01504728466932416, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 500, \"Method\": \"HAL\", \"mean_training_time\": 0.25170488357543946, \"std_training_time\": 0.03560623266536873, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 500, \"Method\": \"HAR\", \"mean_training_time\": 0.0016631603240966797, \"std_training_time\": 0.0016521278651729196, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 500, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.024227094650268555, \"std_training_time\": 0.020413854968180715, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 600, \"Method\": \"HAL\", \"mean_training_time\": 0.493070125579834, \"std_training_time\": 0.050859489610563864, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 600, \"Method\": \"HAR\", \"mean_training_time\": 0.0018861770629882812, \"std_training_time\": 0.0006658796247560257, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 600, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.03156733512878418, \"std_training_time\": 0.023659715197927308, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 700, \"Method\": \"HAL\", \"mean_training_time\": 0.7455812454223633, \"std_training_time\": 0.08334733129885695, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 700, \"Method\": \"HAR\", \"mean_training_time\": 0.013454437255859375, \"std_training_time\": 0.008919311501538298, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 700, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.27872090339660643, \"std_training_time\": 0.012870494552710056, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 800, \"Method\": \"HAL\", \"mean_training_time\": 0.7847572326660156, \"std_training_time\": 0.0596152578510105, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 800, \"Method\": \"HAR\", \"mean_training_time\": 0.01953296661376953, \"std_training_time\": 0.006599946421007119, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 800, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.2872988224029541, \"std_training_time\": 0.038276535300494886, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 900, \"Method\": \"HAL\", \"mean_training_time\": 1.16708984375, \"std_training_time\": 0.0820167178003984, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 900, \"Method\": \"HAR\", \"mean_training_time\": 0.02116236686706543, \"std_training_time\": 0.004204811512582823, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 900, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.2953651905059814, \"std_training_time\": 0.0462919950915067, \"d\": 1, \"dgp_type\": \"Jump\"}], \"data-aa419d3ea4b80fba00ead84438884322\": [{\"Sample Size\": 100, \"Method\": \"HAL\", \"mean_training_time\": 0.008281230926513672, \"std_training_time\": 0.003758964839219602, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 100, \"Method\": \"HAR\", \"mean_training_time\": 0.0005013465881347657, \"std_training_time\": 0.0003462655963180511, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 100, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.005560111999511719, \"std_training_time\": 0.0037769053543921785, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 200, \"Method\": \"HAL\", \"mean_training_time\": 0.02630648612976074, \"std_training_time\": 0.00414162240980405, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 200, \"Method\": \"HAR\", \"mean_training_time\": 0.0003223896026611328, \"std_training_time\": 7.489152247748691e-06, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 200, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.008604907989501953, \"std_training_time\": 0.005644312203099131, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 300, \"Method\": \"HAL\", \"mean_training_time\": 0.10563130378723144, \"std_training_time\": 0.02451850726810689, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 300, \"Method\": \"HAR\", \"mean_training_time\": 0.000735330581665039, \"std_training_time\": 0.0006572717101295572, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 300, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.007601165771484375, \"std_training_time\": 0.003407173279208183, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 400, \"Method\": \"HAL\", \"mean_training_time\": 0.12522974014282226, \"std_training_time\": 0.012426614218837157, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 400, \"Method\": \"HAR\", \"mean_training_time\": 0.0005235671997070312, \"std_training_time\": 4.370252226146358e-05, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 400, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.011871051788330079, \"std_training_time\": 0.005012670320713564, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 500, \"Method\": \"HAL\", \"mean_training_time\": 0.23289170265197753, \"std_training_time\": 0.025489547857864094, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 500, \"Method\": \"HAR\", \"mean_training_time\": 0.0010766983032226562, \"std_training_time\": 0.0006588147520738817, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 500, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.021822452545166016, \"std_training_time\": 0.011638092806182101, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 600, \"Method\": \"HAL\", \"mean_training_time\": 0.43407745361328126, \"std_training_time\": 0.06207968083428509, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 600, \"Method\": \"HAR\", \"mean_training_time\": 0.0006955146789550781, \"std_training_time\": 3.1331866266249755e-06, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 600, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.02429041862487793, \"std_training_time\": 0.003830213186074073, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 700, \"Method\": \"HAL\", \"mean_training_time\": 0.764986801147461, \"std_training_time\": 0.07146665023724878, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 700, \"Method\": \"HAR\", \"mean_training_time\": 0.019858360290527344, \"std_training_time\": 0.005700658824105383, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 700, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.27646465301513673, \"std_training_time\": 0.007585275488671764, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 800, \"Method\": \"HAL\", \"mean_training_time\": 0.7905238151550293, \"std_training_time\": 0.09214192564813874, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 800, \"Method\": \"HAR\", \"mean_training_time\": 0.028452444076538085, \"std_training_time\": 0.030110428750734802, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 800, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.2815962314605713, \"std_training_time\": 0.0064446239492298016, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 900, \"Method\": \"HAL\", \"mean_training_time\": 1.2669930934906006, \"std_training_time\": 0.10385757811347769, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 900, \"Method\": \"HAR\", \"mean_training_time\": 0.0226315975189209, \"std_training_time\": 0.011538184007070693, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 900, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.2932867527008057, \"std_training_time\": 0.01698432319927388, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}], \"data-2ab6b26efc991e90e000df889f071971\": [{\"Sample Size\": 100, \"Method\": \"HAL\", \"mean_training_time\": 0.012191390991210938, \"std_training_time\": 0.0027663134468511683, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 100, \"Method\": \"HAR\", \"mean_training_time\": 0.00037522315979003905, \"std_training_time\": 6.884300863495923e-05, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 100, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.0043567180633544925, \"std_training_time\": 0.0008765432164366104, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 200, \"Method\": \"HAL\", \"mean_training_time\": 0.03169536590576172, \"std_training_time\": 0.00419649062954143, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 200, \"Method\": \"HAR\", \"mean_training_time\": 0.0006527423858642579, \"std_training_time\": 0.0003869467580189653, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 200, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.01618022918701172, \"std_training_time\": 0.015831626336183253, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 300, \"Method\": \"HAL\", \"mean_training_time\": 0.1221764087677002, \"std_training_time\": 0.015730369254183908, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 300, \"Method\": \"HAR\", \"mean_training_time\": 0.0004612445831298828, \"std_training_time\": 3.04423276165508e-05, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 300, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.020463180541992188, \"std_training_time\": 0.013780617279145051, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 400, \"Method\": \"HAL\", \"mean_training_time\": 0.1587188720703125, \"std_training_time\": 0.04404076305616364, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 400, \"Method\": \"HAR\", \"mean_training_time\": 0.0010879039764404297, \"std_training_time\": 0.0009776112754429935, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 400, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.0339846134185791, \"std_training_time\": 0.021132642531664112, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 500, \"Method\": \"HAL\", \"mean_training_time\": 0.31882400512695314, \"std_training_time\": 0.03518891422789902, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 500, \"Method\": \"HAR\", \"mean_training_time\": 0.0021332263946533202, \"std_training_time\": 0.0011720106708086732, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 500, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.08326168060302734, \"std_training_time\": 0.10076469939118982, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 600, \"Method\": \"HAL\", \"mean_training_time\": 0.6738472938537597, \"std_training_time\": 0.07820547525356814, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 600, \"Method\": \"HAR\", \"mean_training_time\": 0.002579402923583984, \"std_training_time\": 0.0027270602561442225, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 600, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.045247650146484374, \"std_training_time\": 0.011535498508062209, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 700, \"Method\": \"HAL\", \"mean_training_time\": 1.287719440460205, \"std_training_time\": 0.11610478756662646, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 700, \"Method\": \"HAR\", \"mean_training_time\": 0.024347496032714844, \"std_training_time\": 0.013099171932530022, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 700, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.29918665885925294, \"std_training_time\": 0.02146123920262593, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 800, \"Method\": \"HAL\", \"mean_training_time\": 1.2541823863983155, \"std_training_time\": 0.3101109942619622, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 800, \"Method\": \"HAR\", \"mean_training_time\": 0.03407521247863769, \"std_training_time\": 0.007491612746579335, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 800, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.3153659820556641, \"std_training_time\": 0.029768125592261704, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 900, \"Method\": \"HAL\", \"mean_training_time\": 2.268816423416138, \"std_training_time\": 0.24799075920660238, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 900, \"Method\": \"HAR\", \"mean_training_time\": 0.027039051055908203, \"std_training_time\": 0.007878238372636633, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 900, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.3459639072418213, \"std_training_time\": 0.020269885056912684, \"d\": 3, \"dgp_type\": \"Smooth\"}], \"data-3ec00f4ff172a4c6ac116c15f1ec0107\": [{\"Sample Size\": 100, \"Method\": \"HAL\", \"mean_training_time\": 0.012302446365356445, \"std_training_time\": 0.0029275600543995583, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 100, \"Method\": \"HAR\", \"mean_training_time\": 0.0005313396453857422, \"std_training_time\": 0.00024124276451057674, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 100, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.004559087753295899, \"std_training_time\": 0.0017972242707089362, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 200, \"Method\": \"HAL\", \"mean_training_time\": 0.03753218650817871, \"std_training_time\": 0.006440003862386943, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 200, \"Method\": \"HAR\", \"mean_training_time\": 0.00040435791015625, \"std_training_time\": 5.200668355630395e-05, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 200, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.010023736953735351, \"std_training_time\": 0.0076646300141158825, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 300, \"Method\": \"HAL\", \"mean_training_time\": 0.16368327140808106, \"std_training_time\": 0.04085058502890181, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 300, \"Method\": \"HAR\", \"mean_training_time\": 0.0005800247192382813, \"std_training_time\": 0.000244397674408612, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 300, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.01947131156921387, \"std_training_time\": 0.00953874302488878, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 400, \"Method\": \"HAL\", \"mean_training_time\": 0.18223681449890136, \"std_training_time\": 0.04352373543724691, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 400, \"Method\": \"HAR\", \"mean_training_time\": 0.0006315231323242188, \"std_training_time\": 8.444114945946897e-05, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 400, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.019913482666015624, \"std_training_time\": 0.0037180109520698256, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 500, \"Method\": \"HAL\", \"mean_training_time\": 0.3611499786376953, \"std_training_time\": 0.03909530721502609, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 500, \"Method\": \"HAR\", \"mean_training_time\": 0.001375865936279297, \"std_training_time\": 0.0010344916814055767, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 500, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.03370537757873535, \"std_training_time\": 0.01959796620875733, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 600, \"Method\": \"HAL\", \"mean_training_time\": 0.6894583702087402, \"std_training_time\": 0.06454396857391398, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 600, \"Method\": \"HAR\", \"mean_training_time\": 0.002777433395385742, \"std_training_time\": 0.0014857547314956422, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 600, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.07734451293945313, \"std_training_time\": 0.039177020510909676, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 700, \"Method\": \"HAL\", \"mean_training_time\": 1.2262028217315675, \"std_training_time\": 0.1909948573126083, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 700, \"Method\": \"HAR\", \"mean_training_time\": 0.029325103759765624, \"std_training_time\": 0.014066644716572823, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 700, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.3050225734710693, \"std_training_time\": 0.04257278616731282, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 800, \"Method\": \"HAL\", \"mean_training_time\": 1.471930742263794, \"std_training_time\": 0.2566850130443733, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 800, \"Method\": \"HAR\", \"mean_training_time\": 0.02214083671569824, \"std_training_time\": 0.003996478620859957, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 800, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.3275922775268555, \"std_training_time\": 0.014284042103846498, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 900, \"Method\": \"HAL\", \"mean_training_time\": 2.166259527206421, \"std_training_time\": 0.4129530205992733, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 900, \"Method\": \"HAR\", \"mean_training_time\": 0.04111623764038086, \"std_training_time\": 0.005411104833062401, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 900, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.317564582824707, \"std_training_time\": 0.01955045548298517, \"d\": 3, \"dgp_type\": \"Jump\"}], \"data-d57f535b1b14c6613813d02d790ef533\": [{\"Sample Size\": 100, \"Method\": \"HAL\", \"mean_training_time\": 0.01074376106262207, \"std_training_time\": 0.002544716213630113, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 100, \"Method\": \"HAR\", \"mean_training_time\": 0.0003841400146484375, \"std_training_time\": 0.00010388860806689038, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 100, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.004149627685546875, \"std_training_time\": 0.0011748972623353822, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 200, \"Method\": \"HAL\", \"mean_training_time\": 0.044258499145507814, \"std_training_time\": 0.00754691327506839, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 200, \"Method\": \"HAR\", \"mean_training_time\": 0.0005779266357421875, \"std_training_time\": 0.00041668072043897866, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 200, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.01028299331665039, \"std_training_time\": 0.004755374731785486, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 300, \"Method\": \"HAL\", \"mean_training_time\": 0.12217626571655274, \"std_training_time\": 0.01216307492789941, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 300, \"Method\": \"HAR\", \"mean_training_time\": 0.0011378288269042968, \"std_training_time\": 0.0009262027657571577, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 300, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.011370658874511719, \"std_training_time\": 0.00257331585103934, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 400, \"Method\": \"HAL\", \"mean_training_time\": 0.18515982627868652, \"std_training_time\": 0.032666211891124425, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 400, \"Method\": \"HAR\", \"mean_training_time\": 0.0013462066650390624, \"std_training_time\": 0.0007437044168463246, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 400, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.020690774917602538, \"std_training_time\": 0.008692042827001605, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 500, \"Method\": \"HAL\", \"mean_training_time\": 0.34272451400756837, \"std_training_time\": 0.0328926921939772, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 500, \"Method\": \"HAR\", \"mean_training_time\": 0.0036981582641601564, \"std_training_time\": 0.005243116246961025, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 500, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.028225135803222657, \"std_training_time\": 0.0040466684096212915, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 600, \"Method\": \"HAL\", \"mean_training_time\": 0.7713221549987793, \"std_training_time\": 0.13837757332954398, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 600, \"Method\": \"HAR\", \"mean_training_time\": 0.0009156703948974609, \"std_training_time\": 0.00011069898124020739, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 600, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.05043683052062988, \"std_training_time\": 0.012137623190221727, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 700, \"Method\": \"HAL\", \"mean_training_time\": 1.3749479293823241, \"std_training_time\": 0.07958246862917859, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 700, \"Method\": \"HAR\", \"mean_training_time\": 0.02973465919494629, \"std_training_time\": 0.009421930484047292, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 700, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.30440802574157716, \"std_training_time\": 0.013438885137853993, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 800, \"Method\": \"HAL\", \"mean_training_time\": 1.3579280376434326, \"std_training_time\": 0.2345197882061275, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 800, \"Method\": \"HAR\", \"mean_training_time\": 0.028482627868652344, \"std_training_time\": 0.008503936038764323, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 800, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.34439544677734374, \"std_training_time\": 0.04521478082166657, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 900, \"Method\": \"HAL\", \"mean_training_time\": 2.0293627262115477, \"std_training_time\": 0.23538846867721555, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 900, \"Method\": \"HAR\", \"mean_training_time\": 0.024471473693847657, \"std_training_time\": 0.011971569829158374, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 900, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.32392077445983886, \"std_training_time\": 0.013929876551563572, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}], \"data-c55f263b7fbf851d00b0d22d7fe143fa\": [{\"Sample Size\": 100, \"Method\": \"HAL\", \"mean_training_time\": 0.018454313278198242, \"std_training_time\": 0.00216157784559047, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 100, \"Method\": \"HAR\", \"mean_training_time\": 0.0005455493927001953, \"std_training_time\": 0.0003250743294920224, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 100, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.004163932800292969, \"std_training_time\": 0.0010427296781578604, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 200, \"Method\": \"HAL\", \"mean_training_time\": 0.08868331909179687, \"std_training_time\": 0.014224247664941382, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 200, \"Method\": \"HAR\", \"mean_training_time\": 0.0007768154144287109, \"std_training_time\": 0.0005152144788898154, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 200, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.008214664459228516, \"std_training_time\": 0.0016512351533247642, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 300, \"Method\": \"HAL\", \"mean_training_time\": 0.2944002628326416, \"std_training_time\": 0.02852603332478607, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 300, \"Method\": \"HAR\", \"mean_training_time\": 0.0009758472442626953, \"std_training_time\": 0.0005570162961628897, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 300, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.013520765304565429, \"std_training_time\": 0.006199210452640636, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 400, \"Method\": \"HAL\", \"mean_training_time\": 0.4296866416931152, \"std_training_time\": 0.08431752934209584, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 400, \"Method\": \"HAR\", \"mean_training_time\": 0.007999420166015625, \"std_training_time\": 0.013349513461923196, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 400, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.04549660682678223, \"std_training_time\": 0.02701029225297284, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 500, \"Method\": \"HAL\", \"mean_training_time\": 0.8179369449615479, \"std_training_time\": 0.11630916092295077, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 500, \"Method\": \"HAR\", \"mean_training_time\": 0.0015318870544433593, \"std_training_time\": 0.0007705625478326465, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 500, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.04104094505310059, \"std_training_time\": 0.016355821071572733, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 600, \"Method\": \"HAL\", \"mean_training_time\": 1.460207176208496, \"std_training_time\": 0.2622456072311818, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 600, \"Method\": \"HAR\", \"mean_training_time\": 0.004068422317504883, \"std_training_time\": 0.0032412085085141294, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 600, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.05232563018798828, \"std_training_time\": 0.007250387472965422, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 700, \"Method\": \"HAL\", \"mean_training_time\": 2.0957016468048097, \"std_training_time\": 0.106505996457584, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 700, \"Method\": \"HAR\", \"mean_training_time\": 0.031856966018676755, \"std_training_time\": 0.006293972504141478, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 700, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.29039535522460935, \"std_training_time\": 0.0067022139791961125, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 800, \"Method\": \"HAL\", \"mean_training_time\": 1.8501203060150146, \"std_training_time\": 0.08143517733442783, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 800, \"Method\": \"HAR\", \"mean_training_time\": 0.030900335311889647, \"std_training_time\": 0.01029439260285165, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 800, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.31334376335144043, \"std_training_time\": 0.013372695680393107, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 900, \"Method\": \"HAL\", \"mean_training_time\": 3.0443846225738525, \"std_training_time\": 0.5381727644467275, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 900, \"Method\": \"HAR\", \"mean_training_time\": 0.03825898170471191, \"std_training_time\": 0.012019983356330864, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 900, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.34329514503479003, \"std_training_time\": 0.028374631443692105, \"d\": 5, \"dgp_type\": \"Smooth\"}], \"data-481d649dcf387ee8403bc58bc9f636a0\": [{\"Sample Size\": 100, \"Method\": \"HAL\", \"mean_training_time\": 0.01892232894897461, \"std_training_time\": 0.004959303672587004, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 100, \"Method\": \"HAR\", \"mean_training_time\": 0.0004195690155029297, \"std_training_time\": 5.438698313231033e-05, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 100, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.006634521484375, \"std_training_time\": 0.00611593591685023, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 200, \"Method\": \"HAL\", \"mean_training_time\": 0.11074423789978027, \"std_training_time\": 0.01931045749400027, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 200, \"Method\": \"HAR\", \"mean_training_time\": 0.000479888916015625, \"std_training_time\": 9.81201806584917e-06, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 200, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.010628175735473634, \"std_training_time\": 0.008302227643250703, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 300, \"Method\": \"HAL\", \"mean_training_time\": 0.32038216590881347, \"std_training_time\": 0.030730501840270524, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 300, \"Method\": \"HAR\", \"mean_training_time\": 0.0026990413665771485, \"std_training_time\": 0.0022844802616914226, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 300, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.013241386413574219, \"std_training_time\": 0.002477946084981837, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 400, \"Method\": \"HAL\", \"mean_training_time\": 0.4749518871307373, \"std_training_time\": 0.07195440887437807, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 400, \"Method\": \"HAR\", \"mean_training_time\": 0.0024605751037597655, \"std_training_time\": 0.002325277594628454, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 400, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.03635811805725098, \"std_training_time\": 0.0037319977038581128, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 500, \"Method\": \"HAL\", \"mean_training_time\": 0.7959018230438233, \"std_training_time\": 0.10521190974163976, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 500, \"Method\": \"HAR\", \"mean_training_time\": 0.0021038055419921875, \"std_training_time\": 0.0010584237628914232, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 500, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.03886256217956543, \"std_training_time\": 0.01110153144750182, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 600, \"Method\": \"HAL\", \"mean_training_time\": 1.3656509876251222, \"std_training_time\": 0.19438894897274253, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 600, \"Method\": \"HAR\", \"mean_training_time\": 0.0020401477813720703, \"std_training_time\": 0.0011172743105301915, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 600, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.05716443061828613, \"std_training_time\": 0.02137826138275248, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 700, \"Method\": \"HAL\", \"mean_training_time\": 1.9856887340545655, \"std_training_time\": 0.25397269526501787, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 700, \"Method\": \"HAR\", \"mean_training_time\": 0.024115943908691408, \"std_training_time\": 0.00357669550771344, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 700, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.30139594078063964, \"std_training_time\": 0.024652842487774895, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 800, \"Method\": \"HAL\", \"mean_training_time\": 2.10082106590271, \"std_training_time\": 0.2910212140196308, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 800, \"Method\": \"HAR\", \"mean_training_time\": 0.031163406372070313, \"std_training_time\": 0.008562480664393047, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 800, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.3290850162506104, \"std_training_time\": 0.04959554355210972, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 900, \"Method\": \"HAL\", \"mean_training_time\": 3.06772985458374, \"std_training_time\": 0.20366869833071732, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 900, \"Method\": \"HAR\", \"mean_training_time\": 0.03225178718566894, \"std_training_time\": 0.008126904394662878, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 900, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.350799036026001, \"std_training_time\": 0.024071435690161628, \"d\": 5, \"dgp_type\": \"Jump\"}], \"data-a943bd30eee77ee97e65febcda2a267f\": [{\"Sample Size\": 100, \"Method\": \"HAL\", \"mean_training_time\": 0.020473766326904296, \"std_training_time\": 0.003906318449426725, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 100, \"Method\": \"HAR\", \"mean_training_time\": 0.00040574073791503905, \"std_training_time\": 5.563675192225462e-05, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 100, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.003530120849609375, \"std_training_time\": 0.0002315969041882273, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 200, \"Method\": \"HAL\", \"mean_training_time\": 0.09665708541870117, \"std_training_time\": 0.03228711595087848, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 200, \"Method\": \"HAR\", \"mean_training_time\": 0.0017346382141113282, \"std_training_time\": 0.0011517219871277934, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 200, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.013822221755981445, \"std_training_time\": 0.007245748272305477, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 300, \"Method\": \"HAL\", \"mean_training_time\": 0.34165186882019044, \"std_training_time\": 0.028324596448203794, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 300, \"Method\": \"HAR\", \"mean_training_time\": 0.0006674289703369141, \"std_training_time\": 7.028367817038437e-05, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 300, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.020894813537597656, \"std_training_time\": 0.004471879701271802, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 400, \"Method\": \"HAL\", \"mean_training_time\": 0.4430880069732666, \"std_training_time\": 0.033602798396630856, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 400, \"Method\": \"HAR\", \"mean_training_time\": 0.0009474277496337891, \"std_training_time\": 0.0002584041341146666, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 400, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.023876142501831055, \"std_training_time\": 0.009539028079372784, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 500, \"Method\": \"HAL\", \"mean_training_time\": 0.7810667514801025, \"std_training_time\": 0.10274998575297759, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 500, \"Method\": \"HAR\", \"mean_training_time\": 0.005205774307250976, \"std_training_time\": 0.0045925174328363075, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 500, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.23211960792541503, \"std_training_time\": 0.3980730460933838, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 600, \"Method\": \"HAL\", \"mean_training_time\": 1.5746565341949463, \"std_training_time\": 0.261927399485771, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 600, \"Method\": \"HAR\", \"mean_training_time\": 0.0022339820861816406, \"std_training_time\": 0.0011114214191283946, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 600, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.0637052059173584, \"std_training_time\": 0.01819044743665482, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 700, \"Method\": \"HAL\", \"mean_training_time\": 2.087675619125366, \"std_training_time\": 0.18877424774360776, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 700, \"Method\": \"HAR\", \"mean_training_time\": 0.017841815948486328, \"std_training_time\": 0.006258156234047007, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 700, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.32726325988769533, \"std_training_time\": 0.01413677922528125, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 800, \"Method\": \"HAL\", \"mean_training_time\": 2.197293186187744, \"std_training_time\": 0.2517082085916186, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 800, \"Method\": \"HAR\", \"mean_training_time\": 0.03626089096069336, \"std_training_time\": 0.012945452398687808, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 800, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.3374753475189209, \"std_training_time\": 0.039701069456546556, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 900, \"Method\": \"HAL\", \"mean_training_time\": 3.835548973083496, \"std_training_time\": 0.49424621959425247, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 900, \"Method\": \"HAR\", \"mean_training_time\": 0.022222232818603516, \"std_training_time\": 0.006154204148943141, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 900, \"Method\": \"KernelHAR\", \"mean_training_time\": 0.43260040283203127, \"std_training_time\": 0.07469265597139657, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.VConcatChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## GRID OF PLOTS 1: TRAIN TIME VS SAMPLE SIZE FOR ALL DGPS AND D SIZES\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import pickle\n",
    "\n",
    "ALL_DF_FILE_NAMES = \"Training_df_files/all_file_names.pickle\"\n",
    "\n",
    "reshaped_data = []\n",
    "d_sizes = [1, 3, 5] \n",
    "dgp_types = ['Smooth', 'Jump', 'Sinusoidal']  # The order of DGP types for each 'd'\n",
    "\n",
    "# --------------------------------------------------------------------------------- # \n",
    "# if data_frames is not defined (new kernel), load file names from ALL_DF_FILE_NAMES\n",
    "# --------------------------------------------------------------------------------- # \n",
    "if 'data_frames' not in locals():\n",
    "    # Load the file names from the pickle file\n",
    "    with open(ALL_DF_FILE_NAMES, \"rb\") as f:\n",
    "        all_file_names = pickle.load(f)\n",
    "    # Load the dataframes from the pickle files\n",
    "    data_frames = [pd.read_pickle(file_name) for file_name in all_file_names]\n",
    "# --------------------------------------------------------------------------------- # \n",
    "\n",
    "## RESHAPING DATAFRAMES FOR PLOTTING\n",
    "# Assuming data_frames is a list of 9 dataframes in the order mentioned\n",
    "for i, data in enumerate(data_frames):\n",
    "    # Calculate the index for d_sizes and dgp_types\n",
    "    d_index = i // len(dgp_types)\n",
    "    dgp_index = i % len(dgp_types)\n",
    "\n",
    "    # Aggregate results by sample size and method\n",
    "    aggregated_df = data.groupby(['Sample Size', 'Method']).agg(\n",
    "        mean_training_time=pd.NamedAgg(column='training_time', aggfunc='mean'),\n",
    "        std_training_time=pd.NamedAgg(column='training_time', aggfunc='std')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Add 'd' and 'dgp' columns\n",
    "    aggregated_df['d'] = d_sizes[d_index]\n",
    "    aggregated_df['dgp_type'] = dgp_types[dgp_index]\n",
    "\n",
    "    reshaped_data.append(aggregated_df)\n",
    "\n",
    "# Function to create a line plot from an aggregated DataFrame\n",
    "def create_plot_from_df(df, d, dgp_type):\n",
    "    \"\"\"Generate a line plot from an aggregated DataFrame.\"\"\"\n",
    "    line_chart = alt.Chart(df).mark_line(point=True).encode(\n",
    "        x='Sample Size:Q',\n",
    "        y=alt.Y('mean_training_time:Q', title=f\"Mean Training Time (s), d={d}\"),\n",
    "        color='Method:N',\n",
    "        tooltip=['Sample Size', 'Method', 'mean_training_time', 'std_training_time']\n",
    "    ).properties(\n",
    "        title=f\"DGP: {dgp_type}\",\n",
    "        width=400,\n",
    "        height=200\n",
    "    )\n",
    "    return line_chart\n",
    "\n",
    "# Function to arrange plots in a grid\n",
    "def arrange_plots_in_grid(plots, num_cols=3, num_rows=3):\n",
    "    # Create rows of charts\n",
    "    rows = [alt.hconcat(*plots[i:i+num_cols]) for i in range(0, len(plots), num_cols)]\n",
    "    # Combine rows into a single chart\n",
    "    grid = alt.vconcat(*rows)\n",
    "    return grid\n",
    "\n",
    "# Generate all individual line plots, now using the 'd' and 'dgp_type' directly from the dataframes\n",
    "line_plots = [create_plot_from_df(df, df['d'].iloc[0], df['dgp_type'].iloc[0]) for df in reshaped_data]\n",
    "\n",
    "# Arrange the line plots into a 3x3 grid\n",
    "line_grid_chart = arrange_plots_in_grid(line_plots, num_cols=3)\n",
    "\n",
    "# Display the grid chart\n",
    "line_grid_chart.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-e86af30249334a9dbbbccf1d1aa7e35e.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-e86af30249334a9dbbbccf1d1aa7e35e.vega-embed details,\n",
       "  #altair-viz-e86af30249334a9dbbbccf1d1aa7e35e.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-e86af30249334a9dbbbccf1d1aa7e35e\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-e86af30249334a9dbbbccf1d1aa7e35e\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-e86af30249334a9dbbbccf1d1aa7e35e\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"axis\": {\"gridWidth\": 0.5}, \"legend\": {\"labelFontSize\": 14, \"titleFontSize\": 16}, \"title\": {\"color\": \"white\"}}, \"vconcat\": [{\"hconcat\": [{\"data\": {\"name\": \"data-e9a44af6444f624d5bbbe26d26c7af1c\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"field\": \"Method\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"Sample Size\", \"type\": \"quantitative\"}, {\"field\": \"Method\", \"type\": \"nominal\"}, {\"field\": \"mean_mse\", \"type\": \"quantitative\"}, {\"field\": \"std_mse\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Sample Size\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_mse\", \"title\": \"Mean MSE, d=1\", \"type\": \"quantitative\"}}, \"height\": 200, \"title\": \"DGP: Smooth\", \"width\": 400}, {\"data\": {\"name\": \"data-159691e740f8ffbf3bfcb317899a3d80\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"field\": \"Method\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"Sample Size\", \"type\": \"quantitative\"}, {\"field\": \"Method\", \"type\": \"nominal\"}, {\"field\": \"mean_mse\", \"type\": \"quantitative\"}, {\"field\": \"std_mse\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Sample Size\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_mse\", \"title\": \"Mean MSE, d=1\", \"type\": \"quantitative\"}}, \"height\": 200, \"title\": \"DGP: Jump\", \"width\": 400}, {\"data\": {\"name\": \"data-501c52938b1c1f22b60750fd9c9d8648\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"field\": \"Method\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"Sample Size\", \"type\": \"quantitative\"}, {\"field\": \"Method\", \"type\": \"nominal\"}, {\"field\": \"mean_mse\", \"type\": \"quantitative\"}, {\"field\": \"std_mse\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Sample Size\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_mse\", \"title\": \"Mean MSE, d=1\", \"type\": \"quantitative\"}}, \"height\": 200, \"title\": \"DGP: Sinusoidal\", \"width\": 400}]}, {\"hconcat\": [{\"data\": {\"name\": \"data-1241477a678269d876390b40ee9db463\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"field\": \"Method\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"Sample Size\", \"type\": \"quantitative\"}, {\"field\": \"Method\", \"type\": \"nominal\"}, {\"field\": \"mean_mse\", \"type\": \"quantitative\"}, {\"field\": \"std_mse\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Sample Size\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_mse\", \"title\": \"Mean MSE, d=3\", \"type\": \"quantitative\"}}, \"height\": 200, \"title\": \"DGP: Smooth\", \"width\": 400}, {\"data\": {\"name\": \"data-2e5c811e7125815053c10b8fa2d9591e\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"field\": \"Method\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"Sample Size\", \"type\": \"quantitative\"}, {\"field\": \"Method\", \"type\": \"nominal\"}, {\"field\": \"mean_mse\", \"type\": \"quantitative\"}, {\"field\": \"std_mse\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Sample Size\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_mse\", \"title\": \"Mean MSE, d=3\", \"type\": \"quantitative\"}}, \"height\": 200, \"title\": \"DGP: Jump\", \"width\": 400}, {\"data\": {\"name\": \"data-65009035e37b27e19d7d14ff7b8b8da4\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"field\": \"Method\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"Sample Size\", \"type\": \"quantitative\"}, {\"field\": \"Method\", \"type\": \"nominal\"}, {\"field\": \"mean_mse\", \"type\": \"quantitative\"}, {\"field\": \"std_mse\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Sample Size\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_mse\", \"title\": \"Mean MSE, d=3\", \"type\": \"quantitative\"}}, \"height\": 200, \"title\": \"DGP: Sinusoidal\", \"width\": 400}]}, {\"hconcat\": [{\"data\": {\"name\": \"data-e45145fb26e6f991d19c13dc3272a766\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"field\": \"Method\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"Sample Size\", \"type\": \"quantitative\"}, {\"field\": \"Method\", \"type\": \"nominal\"}, {\"field\": \"mean_mse\", \"type\": \"quantitative\"}, {\"field\": \"std_mse\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Sample Size\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_mse\", \"title\": \"Mean MSE, d=5\", \"type\": \"quantitative\"}}, \"height\": 200, \"title\": \"DGP: Smooth\", \"width\": 400}, {\"data\": {\"name\": \"data-99b83f172561b51b970df33f0d1c5343\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"field\": \"Method\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"Sample Size\", \"type\": \"quantitative\"}, {\"field\": \"Method\", \"type\": \"nominal\"}, {\"field\": \"mean_mse\", \"type\": \"quantitative\"}, {\"field\": \"std_mse\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Sample Size\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_mse\", \"title\": \"Mean MSE, d=5\", \"type\": \"quantitative\"}}, \"height\": 200, \"title\": \"DGP: Jump\", \"width\": 400}, {\"data\": {\"name\": \"data-ed771c21ac7f22761836f75fce83f745\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"field\": \"Method\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"Sample Size\", \"type\": \"quantitative\"}, {\"field\": \"Method\", \"type\": \"nominal\"}, {\"field\": \"mean_mse\", \"type\": \"quantitative\"}, {\"field\": \"std_mse\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Sample Size\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_mse\", \"title\": \"Mean MSE, d=5\", \"type\": \"quantitative\"}}, \"height\": 200, \"title\": \"DGP: Sinusoidal\", \"width\": 400}]}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-e9a44af6444f624d5bbbe26d26c7af1c\": [{\"Sample Size\": 100, \"Method\": \"HAL\", \"mean_mse\": 1.3560596196346348, \"std_mse\": 0.4050398503270416, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 100, \"Method\": \"HAR\", \"mean_mse\": 1.3343355569628255, \"std_mse\": 0.3288877020538116, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 100, \"Method\": \"KernelHAR\", \"mean_mse\": 1.2610723943370348, \"std_mse\": 0.18933269567530236, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 200, \"Method\": \"HAL\", \"mean_mse\": 1.2200526140592185, \"std_mse\": 0.23827483992977366, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 200, \"Method\": \"HAR\", \"mean_mse\": 1.2515148538319323, \"std_mse\": 0.33029290138572726, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 200, \"Method\": \"KernelHAR\", \"mean_mse\": 1.134983077004039, \"std_mse\": 0.16078566120071597, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 300, \"Method\": \"HAL\", \"mean_mse\": 1.1246114181762945, \"std_mse\": 0.12345060847926813, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 300, \"Method\": \"HAR\", \"mean_mse\": 1.4761302939885472, \"std_mse\": 0.7669344955375698, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 300, \"Method\": \"KernelHAR\", \"mean_mse\": 1.2167360493645414, \"std_mse\": 0.275673582110852, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 400, \"Method\": \"HAL\", \"mean_mse\": 1.098863974340674, \"std_mse\": 0.061940065974682344, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 400, \"Method\": \"HAR\", \"mean_mse\": 1.0958536864781612, \"std_mse\": 0.07219714489842491, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 400, \"Method\": \"KernelHAR\", \"mean_mse\": 1.0814792847825803, \"std_mse\": 0.06256568175446607, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 500, \"Method\": \"HAL\", \"mean_mse\": 1.1118904530355505, \"std_mse\": 0.1373328170932891, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 500, \"Method\": \"HAR\", \"mean_mse\": 1.1093696052184214, \"std_mse\": 0.14130227787553842, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 500, \"Method\": \"KernelHAR\", \"mean_mse\": 1.0649436372140664, \"std_mse\": 0.09704195836238758, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 600, \"Method\": \"HAL\", \"mean_mse\": 1.163091820252688, \"std_mse\": 0.1451928097393139, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 600, \"Method\": \"HAR\", \"mean_mse\": 1.2115245829706391, \"std_mse\": 0.2109420555550774, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 600, \"Method\": \"KernelHAR\", \"mean_mse\": 1.1471048401617183, \"std_mse\": 0.1441346878494003, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 700, \"Method\": \"HAL\", \"mean_mse\": 1.1281351130647406, \"std_mse\": 0.08743462684986285, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 700, \"Method\": \"HAR\", \"mean_mse\": 1.0985142681482991, \"std_mse\": 0.04111162168994682, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 700, \"Method\": \"KernelHAR\", \"mean_mse\": 1.0899005657954421, \"std_mse\": 0.04452017687244619, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 800, \"Method\": \"HAL\", \"mean_mse\": 1.127784552970272, \"std_mse\": 0.03627547094386122, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 800, \"Method\": \"HAR\", \"mean_mse\": 1.1598796749332765, \"std_mse\": 0.09885542761206713, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 800, \"Method\": \"KernelHAR\", \"mean_mse\": 1.125919823774343, \"std_mse\": 0.06341554538510567, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 900, \"Method\": \"HAL\", \"mean_mse\": 1.1135715245206235, \"std_mse\": 0.03283718494091442, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 900, \"Method\": \"HAR\", \"mean_mse\": 1.1189541938778564, \"std_mse\": 0.04411322589414925, \"d\": 1, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 900, \"Method\": \"KernelHAR\", \"mean_mse\": 1.0825255847887643, \"std_mse\": 0.03963802760784355, \"d\": 1, \"dgp_type\": \"Smooth\"}], \"data-159691e740f8ffbf3bfcb317899a3d80\": [{\"Sample Size\": 100, \"Method\": \"HAL\", \"mean_mse\": 1.3194404995055755, \"std_mse\": 0.19900134122108706, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 100, \"Method\": \"HAR\", \"mean_mse\": 1.2289283996585227, \"std_mse\": 0.2649993212916527, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 100, \"Method\": \"KernelHAR\", \"mean_mse\": 1.222664129484086, \"std_mse\": 0.1959979235796215, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 200, \"Method\": \"HAL\", \"mean_mse\": 1.1191396694241142, \"std_mse\": 0.06937779185110896, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 200, \"Method\": \"HAR\", \"mean_mse\": 1.2230037165141743, \"std_mse\": 0.2411765818594549, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 200, \"Method\": \"KernelHAR\", \"mean_mse\": 1.1939219963192478, \"std_mse\": 0.2643047341043834, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 300, \"Method\": \"HAL\", \"mean_mse\": 1.186361026492341, \"std_mse\": 0.09957334388200755, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 300, \"Method\": \"HAR\", \"mean_mse\": 1.193639826440582, \"std_mse\": 0.07539994703641521, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 300, \"Method\": \"KernelHAR\", \"mean_mse\": 1.1595999059280335, \"std_mse\": 0.09883351953137155, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 400, \"Method\": \"HAL\", \"mean_mse\": 1.0721543484199532, \"std_mse\": 0.12641575391249726, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 400, \"Method\": \"HAR\", \"mean_mse\": 1.1044510029233372, \"std_mse\": 0.1407498892662244, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 400, \"Method\": \"KernelHAR\", \"mean_mse\": 1.0855702752987704, \"std_mse\": 0.1305336736845705, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 500, \"Method\": \"HAL\", \"mean_mse\": 1.2751404039118177, \"std_mse\": 0.18756551405602423, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 500, \"Method\": \"HAR\", \"mean_mse\": 1.4236319059452929, \"std_mse\": 0.36471417372967546, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 500, \"Method\": \"KernelHAR\", \"mean_mse\": 1.2374251566724292, \"std_mse\": 0.13752796345801604, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 600, \"Method\": \"HAL\", \"mean_mse\": 1.1221102161127319, \"std_mse\": 0.22434708147447635, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 600, \"Method\": \"HAR\", \"mean_mse\": 1.1137943453589807, \"std_mse\": 0.16851919072450533, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 600, \"Method\": \"KernelHAR\", \"mean_mse\": 1.1061521529390084, \"std_mse\": 0.21986017195723756, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 700, \"Method\": \"HAL\", \"mean_mse\": 1.071783791717495, \"std_mse\": 0.08302952277373518, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 700, \"Method\": \"HAR\", \"mean_mse\": 1.1136572912135958, \"std_mse\": 0.06909093525237892, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 700, \"Method\": \"KernelHAR\", \"mean_mse\": 1.0745541879928582, \"std_mse\": 0.08266409908641108, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 800, \"Method\": \"HAL\", \"mean_mse\": 1.0435930102516735, \"std_mse\": 0.030398313851677846, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 800, \"Method\": \"HAR\", \"mean_mse\": 1.0471280026502066, \"std_mse\": 0.021494040252468722, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 800, \"Method\": \"KernelHAR\", \"mean_mse\": 1.0217756948540253, \"std_mse\": 0.024593960667341826, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 900, \"Method\": \"HAL\", \"mean_mse\": 1.0009864572495022, \"std_mse\": 0.06306505677180455, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 900, \"Method\": \"HAR\", \"mean_mse\": 1.0319577970520297, \"std_mse\": 0.05156967905681116, \"d\": 1, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 900, \"Method\": \"KernelHAR\", \"mean_mse\": 0.9986106104765593, \"std_mse\": 0.0584499300218322, \"d\": 1, \"dgp_type\": \"Jump\"}], \"data-501c52938b1c1f22b60750fd9c9d8648\": [{\"Sample Size\": 100, \"Method\": \"HAL\", \"mean_mse\": 1.3676349563259058, \"std_mse\": 0.2672383977760216, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 100, \"Method\": \"HAR\", \"mean_mse\": 1.3083694321964647, \"std_mse\": 0.1996757495119971, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 100, \"Method\": \"KernelHAR\", \"mean_mse\": 1.2582562368375385, \"std_mse\": 0.2105442992290097, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 200, \"Method\": \"HAL\", \"mean_mse\": 1.2142691079600274, \"std_mse\": 0.14808852264551628, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 200, \"Method\": \"HAR\", \"mean_mse\": 1.192394442432898, \"std_mse\": 0.15061549659273227, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 200, \"Method\": \"KernelHAR\", \"mean_mse\": 1.168397295743358, \"std_mse\": 0.11393350487389586, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 300, \"Method\": \"HAL\", \"mean_mse\": 1.2325332312135466, \"std_mse\": 0.17354667964223108, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 300, \"Method\": \"HAR\", \"mean_mse\": 1.1710374645250354, \"std_mse\": 0.06662445974843789, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 300, \"Method\": \"KernelHAR\", \"mean_mse\": 1.1436177764943436, \"std_mse\": 0.05622741191990823, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 400, \"Method\": \"HAL\", \"mean_mse\": 1.0536185252525394, \"std_mse\": 0.07280163110660534, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 400, \"Method\": \"HAR\", \"mean_mse\": 1.0855347098476782, \"std_mse\": 0.08821380166678226, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 400, \"Method\": \"KernelHAR\", \"mean_mse\": 1.0862281677740027, \"std_mse\": 0.07478413366360691, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 500, \"Method\": \"HAL\", \"mean_mse\": 1.0929709937565348, \"std_mse\": 0.07088627013953756, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 500, \"Method\": \"HAR\", \"mean_mse\": 1.1071298519696628, \"std_mse\": 0.0921592472733228, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 500, \"Method\": \"KernelHAR\", \"mean_mse\": 1.0838999646790355, \"std_mse\": 0.08899208088070726, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 600, \"Method\": \"HAL\", \"mean_mse\": 1.1028033750186637, \"std_mse\": 0.06867927726614514, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 600, \"Method\": \"HAR\", \"mean_mse\": 1.116588243460716, \"std_mse\": 0.05066965522601237, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 600, \"Method\": \"KernelHAR\", \"mean_mse\": 1.0915361971470727, \"std_mse\": 0.08394566356540645, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 700, \"Method\": \"HAL\", \"mean_mse\": 1.0248312579730634, \"std_mse\": 0.04892634398080593, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 700, \"Method\": \"HAR\", \"mean_mse\": 1.0676891946919589, \"std_mse\": 0.06787880211750684, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 700, \"Method\": \"KernelHAR\", \"mean_mse\": 1.033671088690214, \"std_mse\": 0.046295742298485036, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 800, \"Method\": \"HAL\", \"mean_mse\": 1.0150385293420596, \"std_mse\": 0.08277868845785587, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 800, \"Method\": \"HAR\", \"mean_mse\": 1.0671086647111763, \"std_mse\": 0.09790418003033013, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 800, \"Method\": \"KernelHAR\", \"mean_mse\": 1.0108872275848708, \"std_mse\": 0.06386849099032733, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 900, \"Method\": \"HAL\", \"mean_mse\": 1.0324806355974228, \"std_mse\": 0.03732353742786924, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 900, \"Method\": \"HAR\", \"mean_mse\": 1.121364532503779, \"std_mse\": 0.12591590706245395, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 900, \"Method\": \"KernelHAR\", \"mean_mse\": 1.0414199257635732, \"std_mse\": 0.048288014388178944, \"d\": 1, \"dgp_type\": \"Sinusoidal\"}], \"data-1241477a678269d876390b40ee9db463\": [{\"Sample Size\": 100, \"Method\": \"HAL\", \"mean_mse\": 3.1109196757606297, \"std_mse\": 0.4658087324549038, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 100, \"Method\": \"HAR\", \"mean_mse\": 2.9908828842715023, \"std_mse\": 0.642323803885158, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 100, \"Method\": \"KernelHAR\", \"mean_mse\": 3.475691687387331, \"std_mse\": 0.9587417178737648, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 200, \"Method\": \"HAL\", \"mean_mse\": 2.516223666471605, \"std_mse\": 1.0225991657519915, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 200, \"Method\": \"HAR\", \"mean_mse\": 2.287784602657797, \"std_mse\": 0.990205207643636, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 200, \"Method\": \"KernelHAR\", \"mean_mse\": 2.183318015674869, \"std_mse\": 0.938515531951445, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 300, \"Method\": \"HAL\", \"mean_mse\": 1.631618770121133, \"std_mse\": 0.27012116711956957, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 300, \"Method\": \"HAR\", \"mean_mse\": 1.8367196436377733, \"std_mse\": 0.33788680597206805, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 300, \"Method\": \"KernelHAR\", \"mean_mse\": 1.8236659081403386, \"std_mse\": 0.20495233571533977, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 400, \"Method\": \"HAL\", \"mean_mse\": 1.764832699939933, \"std_mse\": 0.38430412653598495, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 400, \"Method\": \"HAR\", \"mean_mse\": 1.6581797072214932, \"std_mse\": 0.281085536751798, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 400, \"Method\": \"KernelHAR\", \"mean_mse\": 1.661020667138787, \"std_mse\": 0.31661368945024293, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 500, \"Method\": \"HAL\", \"mean_mse\": 1.414700094409011, \"std_mse\": 0.14575368766680005, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 500, \"Method\": \"HAR\", \"mean_mse\": 1.4040484957314583, \"std_mse\": 0.12105303917894489, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 500, \"Method\": \"KernelHAR\", \"mean_mse\": 1.4301766427679214, \"std_mse\": 0.1262869687853446, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 600, \"Method\": \"HAL\", \"mean_mse\": 1.3802862624845815, \"std_mse\": 0.16362859211347258, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 600, \"Method\": \"HAR\", \"mean_mse\": 1.3127503794179503, \"std_mse\": 0.10569533907020869, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 600, \"Method\": \"KernelHAR\", \"mean_mse\": 1.317187985365079, \"std_mse\": 0.10060713434255998, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 700, \"Method\": \"HAL\", \"mean_mse\": 1.4956350729792043, \"std_mse\": 0.11903142800183192, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 700, \"Method\": \"HAR\", \"mean_mse\": 1.3962061351759147, \"std_mse\": 0.20509191394143392, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 700, \"Method\": \"KernelHAR\", \"mean_mse\": 1.4374263878117197, \"std_mse\": 0.20248803911203045, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 800, \"Method\": \"HAL\", \"mean_mse\": 1.3687265738546646, \"std_mse\": 0.06861606396437056, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 800, \"Method\": \"HAR\", \"mean_mse\": 1.4411581507062514, \"std_mse\": 0.20541531096673837, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 800, \"Method\": \"KernelHAR\", \"mean_mse\": 1.4272235780221985, \"std_mse\": 0.10567374373204846, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 900, \"Method\": \"HAL\", \"mean_mse\": 1.3697815477550903, \"std_mse\": 0.08476373773725591, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 900, \"Method\": \"HAR\", \"mean_mse\": 1.3596102400488264, \"std_mse\": 0.10442931446186816, \"d\": 3, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 900, \"Method\": \"KernelHAR\", \"mean_mse\": 1.3989114238003892, \"std_mse\": 0.09904487504280672, \"d\": 3, \"dgp_type\": \"Smooth\"}], \"data-2e5c811e7125815053c10b8fa2d9591e\": [{\"Sample Size\": 100, \"Method\": \"HAL\", \"mean_mse\": 4.124368000122017, \"std_mse\": 1.7089338401273395, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 100, \"Method\": \"HAR\", \"mean_mse\": 3.5049970070249605, \"std_mse\": 1.236679227485297, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 100, \"Method\": \"KernelHAR\", \"mean_mse\": 3.736720287903328, \"std_mse\": 1.1966479867741484, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 200, \"Method\": \"HAL\", \"mean_mse\": 2.112606448203993, \"std_mse\": 0.35558714086151993, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 200, \"Method\": \"HAR\", \"mean_mse\": 1.8741129325918373, \"std_mse\": 0.3563611066967999, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 200, \"Method\": \"KernelHAR\", \"mean_mse\": 2.429450555507836, \"std_mse\": 0.3030878583100517, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 300, \"Method\": \"HAL\", \"mean_mse\": 2.25806778586702, \"std_mse\": 0.693630739039035, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 300, \"Method\": \"HAR\", \"mean_mse\": 2.284295087841289, \"std_mse\": 0.6220053429504901, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 300, \"Method\": \"KernelHAR\", \"mean_mse\": 2.4770792369528727, \"std_mse\": 0.7579992189615674, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 400, \"Method\": \"HAL\", \"mean_mse\": 1.6612971998054693, \"std_mse\": 0.2949650864065051, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 400, \"Method\": \"HAR\", \"mean_mse\": 1.5455388296882098, \"std_mse\": 0.24325531350731192, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 400, \"Method\": \"KernelHAR\", \"mean_mse\": 1.605492004934558, \"std_mse\": 0.21572229642951146, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 500, \"Method\": \"HAL\", \"mean_mse\": 1.6208894069069562, \"std_mse\": 0.260476419168428, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 500, \"Method\": \"HAR\", \"mean_mse\": 1.5966385837435761, \"std_mse\": 0.36382110187395195, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 500, \"Method\": \"KernelHAR\", \"mean_mse\": 1.644225135253114, \"std_mse\": 0.4125255745202712, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 600, \"Method\": \"HAL\", \"mean_mse\": 1.4859441368073676, \"std_mse\": 0.20416739405439369, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 600, \"Method\": \"HAR\", \"mean_mse\": 1.4860534560941452, \"std_mse\": 0.25384460554684135, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 600, \"Method\": \"KernelHAR\", \"mean_mse\": 1.4558479568366622, \"std_mse\": 0.2646334993906844, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 700, \"Method\": \"HAL\", \"mean_mse\": 1.4761949133495853, \"std_mse\": 0.21095612482573545, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 700, \"Method\": \"HAR\", \"mean_mse\": 1.371852027428374, \"std_mse\": 0.16050276110604567, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 700, \"Method\": \"KernelHAR\", \"mean_mse\": 1.3939639567094353, \"std_mse\": 0.16165121370087884, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 800, \"Method\": \"HAL\", \"mean_mse\": 1.3442521919572532, \"std_mse\": 0.14386360965249292, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 800, \"Method\": \"HAR\", \"mean_mse\": 1.3249170409966464, \"std_mse\": 0.1445170964083515, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 800, \"Method\": \"KernelHAR\", \"mean_mse\": 1.3927922795387335, \"std_mse\": 0.1410139105813038, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 900, \"Method\": \"HAL\", \"mean_mse\": 1.3775681938813693, \"std_mse\": 0.1270081057994011, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 900, \"Method\": \"HAR\", \"mean_mse\": 1.3500717808007676, \"std_mse\": 0.08177453423861625, \"d\": 3, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 900, \"Method\": \"KernelHAR\", \"mean_mse\": 1.3737169891273688, \"std_mse\": 0.11742747197161314, \"d\": 3, \"dgp_type\": \"Jump\"}], \"data-65009035e37b27e19d7d14ff7b8b8da4\": [{\"Sample Size\": 100, \"Method\": \"HAL\", \"mean_mse\": 3.071665733862853, \"std_mse\": 0.5800806707975201, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 100, \"Method\": \"HAR\", \"mean_mse\": 3.2381054228637955, \"std_mse\": 0.9714831976987442, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 100, \"Method\": \"KernelHAR\", \"mean_mse\": 3.0447993384661833, \"std_mse\": 0.3894805171198077, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 200, \"Method\": \"HAL\", \"mean_mse\": 2.4086898087389312, \"std_mse\": 1.0285180327886982, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 200, \"Method\": \"HAR\", \"mean_mse\": 2.2602560980685027, \"std_mse\": 0.8072374626940028, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 200, \"Method\": \"KernelHAR\", \"mean_mse\": 2.4602607356971795, \"std_mse\": 0.8156718225239209, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 300, \"Method\": \"HAL\", \"mean_mse\": 1.8840509822467073, \"std_mse\": 0.39717390546646975, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 300, \"Method\": \"HAR\", \"mean_mse\": 1.7231385936359433, \"std_mse\": 0.3118025151684437, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 300, \"Method\": \"KernelHAR\", \"mean_mse\": 2.104283497884182, \"std_mse\": 1.0342838233275555, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 400, \"Method\": \"HAL\", \"mean_mse\": 2.0547646639445976, \"std_mse\": 0.43883313212282604, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 400, \"Method\": \"HAR\", \"mean_mse\": 1.7311583223948852, \"std_mse\": 0.33472048990077424, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 400, \"Method\": \"KernelHAR\", \"mean_mse\": 1.7182346908461021, \"std_mse\": 0.2671547772174239, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 500, \"Method\": \"HAL\", \"mean_mse\": 1.6427598173987505, \"std_mse\": 0.21240511092401426, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 500, \"Method\": \"HAR\", \"mean_mse\": 1.5348702008208066, \"std_mse\": 0.14718370362013694, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 500, \"Method\": \"KernelHAR\", \"mean_mse\": 1.5185805260664176, \"std_mse\": 0.10880469467865164, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 600, \"Method\": \"HAL\", \"mean_mse\": 1.5422223223061204, \"std_mse\": 0.1446378160006516, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 600, \"Method\": \"HAR\", \"mean_mse\": 1.4234243094162133, \"std_mse\": 0.24832232918934855, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 600, \"Method\": \"KernelHAR\", \"mean_mse\": 1.4247361444623505, \"std_mse\": 0.13658095524548858, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 700, \"Method\": \"HAL\", \"mean_mse\": 1.396909520449962, \"std_mse\": 0.10807111426407626, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 700, \"Method\": \"HAR\", \"mean_mse\": 1.3484365394829088, \"std_mse\": 0.061950608659840395, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 700, \"Method\": \"KernelHAR\", \"mean_mse\": 1.410956231457114, \"std_mse\": 0.11009012170891153, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 800, \"Method\": \"HAL\", \"mean_mse\": 1.5066083817194422, \"std_mse\": 0.2236824306963106, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 800, \"Method\": \"HAR\", \"mean_mse\": 1.3663017634622392, \"std_mse\": 0.15474338691606626, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 800, \"Method\": \"KernelHAR\", \"mean_mse\": 1.4285077923143712, \"std_mse\": 0.1675962129441537, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 900, \"Method\": \"HAL\", \"mean_mse\": 1.3837202651915361, \"std_mse\": 0.2150890998852316, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 900, \"Method\": \"HAR\", \"mean_mse\": 1.3134424439123649, \"std_mse\": 0.1421793188212546, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 900, \"Method\": \"KernelHAR\", \"mean_mse\": 1.3522874639278415, \"std_mse\": 0.15067911082611582, \"d\": 3, \"dgp_type\": \"Sinusoidal\"}], \"data-e45145fb26e6f991d19c13dc3272a766\": [{\"Sample Size\": 100, \"Method\": \"HAL\", \"mean_mse\": 5.404710549427332, \"std_mse\": 1.1150731833022045, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 100, \"Method\": \"HAR\", \"mean_mse\": 4.414212969723546, \"std_mse\": 0.7554464473465515, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 100, \"Method\": \"KernelHAR\", \"mean_mse\": 5.005652980470944, \"std_mse\": 1.037773947655041, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 200, \"Method\": \"HAL\", \"mean_mse\": 4.440332102720189, \"std_mse\": 0.8600970608829724, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 200, \"Method\": \"HAR\", \"mean_mse\": 3.27990610857922, \"std_mse\": 0.5770010670828447, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 200, \"Method\": \"KernelHAR\", \"mean_mse\": 3.71726529857688, \"std_mse\": 0.4880005665871175, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 300, \"Method\": \"HAL\", \"mean_mse\": 2.6888849930940966, \"std_mse\": 0.46256954280379886, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 300, \"Method\": \"HAR\", \"mean_mse\": 2.59986799533404, \"std_mse\": 0.4949793604123367, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 300, \"Method\": \"KernelHAR\", \"mean_mse\": 2.8605534518578803, \"std_mse\": 0.28246160603841586, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 400, \"Method\": \"HAL\", \"mean_mse\": 2.4143679670932174, \"std_mse\": 0.17114496410508467, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 400, \"Method\": \"HAR\", \"mean_mse\": 2.222709175429155, \"std_mse\": 0.09688608844964676, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 400, \"Method\": \"KernelHAR\", \"mean_mse\": 2.3552105253592863, \"std_mse\": 0.3596467681574568, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 500, \"Method\": \"HAL\", \"mean_mse\": 2.2289098877084994, \"std_mse\": 0.38752479283121455, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 500, \"Method\": \"HAR\", \"mean_mse\": 1.9488452709576944, \"std_mse\": 0.3865694886885856, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 500, \"Method\": \"KernelHAR\", \"mean_mse\": 2.1830603030890776, \"std_mse\": 0.4741449618664027, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 600, \"Method\": \"HAL\", \"mean_mse\": 2.117298960110487, \"std_mse\": 0.2829752863848116, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 600, \"Method\": \"HAR\", \"mean_mse\": 1.9554406610072395, \"std_mse\": 0.27019224994098245, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 600, \"Method\": \"KernelHAR\", \"mean_mse\": 2.0403708346479172, \"std_mse\": 0.09597558377014305, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 700, \"Method\": \"HAL\", \"mean_mse\": 2.0360967598587387, \"std_mse\": 0.3141628505181093, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 700, \"Method\": \"HAR\", \"mean_mse\": 1.933999320999766, \"std_mse\": 0.3161799049441373, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 700, \"Method\": \"KernelHAR\", \"mean_mse\": 1.9189013934550583, \"std_mse\": 0.21102687934346057, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 800, \"Method\": \"HAL\", \"mean_mse\": 1.8979149543303364, \"std_mse\": 0.22036900386391667, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 800, \"Method\": \"HAR\", \"mean_mse\": 1.783658097494396, \"std_mse\": 0.17706460024873458, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 800, \"Method\": \"KernelHAR\", \"mean_mse\": 1.8077363327723313, \"std_mse\": 0.1546836722954999, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 900, \"Method\": \"HAL\", \"mean_mse\": 1.7807223861754047, \"std_mse\": 0.3155614502367915, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 900, \"Method\": \"HAR\", \"mean_mse\": 1.6006263087997474, \"std_mse\": 0.14230315645066186, \"d\": 5, \"dgp_type\": \"Smooth\"}, {\"Sample Size\": 900, \"Method\": \"KernelHAR\", \"mean_mse\": 1.6575079972104287, \"std_mse\": 0.17577392871674083, \"d\": 5, \"dgp_type\": \"Smooth\"}], \"data-99b83f172561b51b970df33f0d1c5343\": [{\"Sample Size\": 100, \"Method\": \"HAL\", \"mean_mse\": 5.113847806026842, \"std_mse\": 1.4302496536008809, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 100, \"Method\": \"HAR\", \"mean_mse\": 4.782826672144459, \"std_mse\": 0.4580288621113926, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 100, \"Method\": \"KernelHAR\", \"mean_mse\": 4.848190483852841, \"std_mse\": 1.2425564426977858, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 200, \"Method\": \"HAL\", \"mean_mse\": 3.77411353993037, \"std_mse\": 1.1066477519539393, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 200, \"Method\": \"HAR\", \"mean_mse\": 2.935957483725311, \"std_mse\": 0.7108319059086259, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 200, \"Method\": \"KernelHAR\", \"mean_mse\": 3.5454875235265275, \"std_mse\": 0.9384925429342988, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 300, \"Method\": \"HAL\", \"mean_mse\": 2.856970324881739, \"std_mse\": 0.5996771038133244, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 300, \"Method\": \"HAR\", \"mean_mse\": 2.5630094752831574, \"std_mse\": 0.3620562856455523, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 300, \"Method\": \"KernelHAR\", \"mean_mse\": 2.801487747798596, \"std_mse\": 0.2962807061355108, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 400, \"Method\": \"HAL\", \"mean_mse\": 2.360524834911717, \"std_mse\": 0.16921318549077663, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 400, \"Method\": \"HAR\", \"mean_mse\": 2.081640492708053, \"std_mse\": 0.03882444970201023, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 400, \"Method\": \"KernelHAR\", \"mean_mse\": 2.304485052481173, \"std_mse\": 0.1552469885194638, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 500, \"Method\": \"HAL\", \"mean_mse\": 2.6403562171191703, \"std_mse\": 0.40160440257025987, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 500, \"Method\": \"HAR\", \"mean_mse\": 2.1527422746647216, \"std_mse\": 0.2336370534860189, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 500, \"Method\": \"KernelHAR\", \"mean_mse\": 2.2914034022746517, \"std_mse\": 0.47368757106658427, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 600, \"Method\": \"HAL\", \"mean_mse\": 2.0733997939339983, \"std_mse\": 0.1564035345227613, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 600, \"Method\": \"HAR\", \"mean_mse\": 1.9266644995669444, \"std_mse\": 0.05751064860654002, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 600, \"Method\": \"KernelHAR\", \"mean_mse\": 2.0733637361572463, \"std_mse\": 0.15892444148290655, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 700, \"Method\": \"HAL\", \"mean_mse\": 2.1165474884079254, \"std_mse\": 0.25755512378137496, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 700, \"Method\": \"HAR\", \"mean_mse\": 1.9684156083686315, \"std_mse\": 0.15542221245831156, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 700, \"Method\": \"KernelHAR\", \"mean_mse\": 1.989152390096122, \"std_mse\": 0.14067012292478884, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 800, \"Method\": \"HAL\", \"mean_mse\": 1.894447589492787, \"std_mse\": 0.18326791910902593, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 800, \"Method\": \"HAR\", \"mean_mse\": 1.6936557136504267, \"std_mse\": 0.11236459836035291, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 800, \"Method\": \"KernelHAR\", \"mean_mse\": 1.7450366853077632, \"std_mse\": 0.10136059077790768, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 900, \"Method\": \"HAL\", \"mean_mse\": 1.731448621405925, \"std_mse\": 0.1774312585105913, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 900, \"Method\": \"HAR\", \"mean_mse\": 1.7857462495386713, \"std_mse\": 0.1618839180001027, \"d\": 5, \"dgp_type\": \"Jump\"}, {\"Sample Size\": 900, \"Method\": \"KernelHAR\", \"mean_mse\": 1.7505645396886187, \"std_mse\": 0.18526780320369945, \"d\": 5, \"dgp_type\": \"Jump\"}], \"data-ed771c21ac7f22761836f75fce83f745\": [{\"Sample Size\": 100, \"Method\": \"HAL\", \"mean_mse\": 5.4022764550143245, \"std_mse\": 1.3517867355896498, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 100, \"Method\": \"HAR\", \"mean_mse\": 4.52592926535823, \"std_mse\": 1.0681895712744076, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 100, \"Method\": \"KernelHAR\", \"mean_mse\": 5.5470578765609115, \"std_mse\": 0.80019801466079, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 200, \"Method\": \"HAL\", \"mean_mse\": 3.9082617590584974, \"std_mse\": 0.24416255052802108, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 200, \"Method\": \"HAR\", \"mean_mse\": 2.850136569674353, \"std_mse\": 0.43344991938400573, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 200, \"Method\": \"KernelHAR\", \"mean_mse\": 3.1056251500935574, \"std_mse\": 0.5562451757790362, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 300, \"Method\": \"HAL\", \"mean_mse\": 3.238652628467699, \"std_mse\": 1.1801986395517217, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 300, \"Method\": \"HAR\", \"mean_mse\": 2.7632061438987643, \"std_mse\": 0.8397593201355797, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 300, \"Method\": \"KernelHAR\", \"mean_mse\": 2.9670379966238345, \"std_mse\": 0.5244520033652794, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 400, \"Method\": \"HAL\", \"mean_mse\": 3.215674380607686, \"std_mse\": 1.0215117675267325, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 400, \"Method\": \"HAR\", \"mean_mse\": 2.4021040641751537, \"std_mse\": 0.5432010625025355, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 400, \"Method\": \"KernelHAR\", \"mean_mse\": 2.5458674616447854, \"std_mse\": 0.4772485784362093, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 500, \"Method\": \"HAL\", \"mean_mse\": 2.3764697187886448, \"std_mse\": 0.27256976072732986, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 500, \"Method\": \"HAR\", \"mean_mse\": 1.8868127341658567, \"std_mse\": 0.2658636808747746, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 500, \"Method\": \"KernelHAR\", \"mean_mse\": 2.0111243241733523, \"std_mse\": 0.2694328403839199, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 600, \"Method\": \"HAL\", \"mean_mse\": 1.950791614482134, \"std_mse\": 0.11741379896752313, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 600, \"Method\": \"HAR\", \"mean_mse\": 1.8200919537955236, \"std_mse\": 0.16193011022931367, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 600, \"Method\": \"KernelHAR\", \"mean_mse\": 1.8621974983174128, \"std_mse\": 0.08504921151806838, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 700, \"Method\": \"HAL\", \"mean_mse\": 2.319541234999748, \"std_mse\": 0.41869152359802947, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 700, \"Method\": \"HAR\", \"mean_mse\": 1.9889079189142698, \"std_mse\": 0.22377134807979696, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 700, \"Method\": \"KernelHAR\", \"mean_mse\": 2.000881652282579, \"std_mse\": 0.21404105978343665, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 800, \"Method\": \"HAL\", \"mean_mse\": 1.943146410187183, \"std_mse\": 0.37211800661091143, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 800, \"Method\": \"HAR\", \"mean_mse\": 1.8794254637002665, \"std_mse\": 0.4544217064566359, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 800, \"Method\": \"KernelHAR\", \"mean_mse\": 1.9750826100255068, \"std_mse\": 0.4334143580180152, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 900, \"Method\": \"HAL\", \"mean_mse\": 1.7174401878975754, \"std_mse\": 0.1364989020934758, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 900, \"Method\": \"HAR\", \"mean_mse\": 1.6948850484374396, \"std_mse\": 0.14617945060971202, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}, {\"Sample Size\": 900, \"Method\": \"KernelHAR\", \"mean_mse\": 1.6535695529804522, \"std_mse\": 0.1436900808970189, \"d\": 5, \"dgp_type\": \"Sinusoidal\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.VConcatChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# Assuming data_frames is a list of 9 dataframes in the order mentioned\n",
    "reshaped_data_mse = []\n",
    "for i, data in enumerate(data_frames):\n",
    "    # Calculate the index for d_sizes and dgp_types\n",
    "    d_index = i // len(dgp_types)\n",
    "    dgp_index = i % len(dgp_types)\n",
    "\n",
    "    # Aggregate results by sample size and method for MSE\n",
    "    aggregated_df_mse = data.groupby(['Sample Size', 'Method']).agg(\n",
    "        mean_mse=pd.NamedAgg(column='MSE', aggfunc='mean'),\n",
    "        std_mse=pd.NamedAgg(column='MSE', aggfunc='std')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Add 'd' and 'dgp' columns\n",
    "    aggregated_df_mse['d'] = d_sizes[d_index]\n",
    "    aggregated_df_mse['dgp_type'] = dgp_types[dgp_index]\n",
    "\n",
    "    reshaped_data_mse.append(aggregated_df_mse)\n",
    "\n",
    "def create_mse_plot_from_df(df, d, dgp_type):\n",
    "    \"\"\"Generate a line plot from an aggregated DataFrame for MSE.\"\"\"\n",
    "    mse_chart = alt.Chart(df).mark_line(point=True).encode(\n",
    "        x='Sample Size:Q',\n",
    "        y=alt.Y('mean_mse:Q', title=f\"Mean MSE, d={d}\"),\n",
    "        color='Method:N',\n",
    "        tooltip=['Sample Size', 'Method', 'mean_mse', 'std_mse']\n",
    "    ).properties(\n",
    "        title=f\"DGP: {dgp_type}\",\n",
    "        width=400,\n",
    "        height=200\n",
    "    )\n",
    "    return mse_chart\n",
    "\n",
    "def arrange_plots_in_grid(plots, num_cols=3):\n",
    "    rows = [alt.hconcat(*plots[i:i+num_cols]) for i in range(0, len(plots), num_cols)]\n",
    "    grid = alt.vconcat(*rows).configure_title(\n",
    "        color='white'\n",
    "    ).configure_axis(\n",
    "        # gridColor='white',\n",
    "        # titleColor='white',\n",
    "        # labelColor='white',\n",
    "        # domainColor='white',\n",
    "        # tickColor='white',\n",
    "        gridWidth=0.5\n",
    "    ).configure_legend(\n",
    "        # labelColor='white',\n",
    "        # titleColor='white',\n",
    "        labelFontSize=14,\n",
    "        titleFontSize=16\n",
    "    ).properties(\n",
    "        # background='black'\n",
    "    )\n",
    "    return grid\n",
    "\n",
    "# Generate all individual MSE line plots\n",
    "mse_line_plots = [create_mse_plot_from_df(df, df['d'].iloc[0], df['dgp_type'].iloc[0]) for df in reshaped_data_mse]\n",
    "\n",
    "# Arrange the MSE line plots into a 3x3 grid\n",
    "mse_line_grid_chart = arrange_plots_in_grid(mse_line_plots, num_cols=3)\n",
    "\n",
    "# Display the grid chart for MSE\n",
    "mse_line_grid_chart.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all methods again\n",
    "from highly_adaptive_lasso import HAL\n",
    "from highly_adaptive_ridge import HAR\n",
    "from kernel_har import KernelHAR\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from run_trials import RunTrials\n",
    "import warnings\n",
    "from train_time_plotter import TrainTimePlotter\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time for HAR: 0.5682401657104492\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from data_generators import SmoothDataGenerator, JumpDataGenerator, SinusoidalDataGenerator\n",
    "\n",
    "n = 1000\n",
    "d = 3\n",
    "X, Y = SmoothDataGenerator.generate_data(n, d)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "# Train and record train time\n",
    "method = HAR()\n",
    "# fit the model and record training time\n",
    "import time\n",
    "start_time = time.time()\n",
    "method.fit(X_train, Y_train)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# print the training time for method\n",
    "print(f\"Training time for HAR: {training_time}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing kernel matrix for K_train for fold:  [   0    1    2 ... 6550 6551 6552]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# import all methods again\n",
    "from highly_adaptive_lasso import HAL\n",
    "from highly_adaptive_ridge import HAR\n",
    "from kernel_har import KernelHAR\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from run_trials import RunTrials\n",
    "import warnings\n",
    "from train_time_plotter import TrainTimePlotter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# try testing HAR on some real data\n",
    "# Load the data and split into X and Y\n",
    "data = pd.read_csv(\"/Users/alexhagemeister/Downloads/csv/kin8nm.csv\")\n",
    "\n",
    "# Check for missing values\n",
    "if data.isnull().values.any():\n",
    "    print(\"Data contains missing values. Please handle them before training.\")\n",
    "    data = data.dropna()\n",
    "\n",
    "# Ensure all data are numeric\n",
    "if not all(np.issubdtype(dtype, np.number) for dtype in data.dtypes):\n",
    "    print(\"Data contains non-numeric values. Please convert them to numeric before training.\")\n",
    "\n",
    "# Last column is the target\n",
    "X = data.iloc[:, :-1].values\n",
    "Y = data.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "# Train and record train time\n",
    "method = KernelHAR()\n",
    "# fit the model and record training time\n",
    "import time\n",
    "start_time = time.time()\n",
    "method.fit(X_train, Y_train)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# print the training time for method\n",
    "print(f\"Training time for HAR: {training_time}\")\n",
    "\n",
    "#---- PLOTTING ----#\n",
    "\n",
    "print(\"lambdas: \", method.lambdas)\n",
    "print(\"CV MSEs: \", method.cv_mses)\n",
    "\n",
    "# plot cv mse as function of lambda using altair\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from the cross-validated MSEs\n",
    "df = pd.DataFrame({'Lambda': method.lambdas, 'CV MSE': method.cv_mses})\n",
    "\n",
    "# Create a line plot of CV MSE as a function of lambda\n",
    "line_chart = alt.Chart(df).mark_line(point=True).encode(\n",
    "    x='Lambda:Q',\n",
    "    y='CV MSE:Q'\n",
    ").properties(\n",
    "    title='Cross-Validated MSE as a Function of Lambda',\n",
    "    width=400,\n",
    "    height=200\n",
    ")\n",
    "\n",
    "# Display the line chart\n",
    "line_chart.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambdas:  [0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
      "CV MSEs:  [ 1.31914686  1.32847902  1.4203525   2.18205082  6.26085194 22.0048786 ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-a954528b2d4348cda670c80f35970888.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-a954528b2d4348cda670c80f35970888.vega-embed details,\n",
       "  #altair-viz-a954528b2d4348cda670c80f35970888.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-a954528b2d4348cda670c80f35970888\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-a954528b2d4348cda670c80f35970888\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-a954528b2d4348cda670c80f35970888\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-c1e02c8c953fd0ba12fed1a20eaf2fbc\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"x\": {\"field\": \"Lambda\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"CV MSE\", \"type\": \"quantitative\"}}, \"height\": 200, \"title\": \"Cross-Validated MSE as a Function of Lambda\", \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-c1e02c8c953fd0ba12fed1a20eaf2fbc\": [{\"Lambda\": 0.01, \"CV MSE\": 1.3191468583192087}, {\"Lambda\": 0.1, \"CV MSE\": 1.3284790185807853}, {\"Lambda\": 1.0, \"CV MSE\": 1.42035250485946}, {\"Lambda\": 10.0, \"CV MSE\": 2.182050824237962}, {\"Lambda\": 100.0, \"CV MSE\": 6.2608519398705935}, {\"Lambda\": 1000.0, \"CV MSE\": 22.00487859873463}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"lambdas: \", method.lambdas)\n",
    "print(\"CV MSEs: \", method.cv_mses)\n",
    "\n",
    "# plot cv mse as function of lambda using altair\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from the cross-validated MSEs\n",
    "df = pd.DataFrame({'Lambda': method.lambdas, 'CV MSE': method.cv_mses})\n",
    "\n",
    "# Create a line plot of CV MSE as a function of lambda\n",
    "line_chart = alt.Chart(df).mark_line(point=True).encode(\n",
    "    x='Lambda:Q',\n",
    "    y='CV MSE:Q'\n",
    ").properties(\n",
    "    title='Cross-Validated MSE as a Function of Lambda',\n",
    "    width=400,\n",
    "    height=200\n",
    ")\n",
    "\n",
    "# Display the line chart\n",
    "line_chart.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11040"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(method.kernel_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "built comparison matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-3073, -1246,  -926, ..., -1285, -1539, -1121],\n",
       "       [-1246, -2448, -1157, ...,  -860, -1567, -1047],\n",
       "       [ -926, -1157, -2371, ...,  -723, -1643,  -763],\n",
       "       ...,\n",
       "       [-1285,  -860,  -723, ..., -3791, -1038, -1755],\n",
       "       [-1539, -1567, -1643, ..., -1038, -6205, -1782],\n",
       "       [-1121, -1047,  -763, ..., -1755, -1782, -3441]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import all methods again\n",
    "from highly_adaptive_lasso import HAL\n",
    "from highly_adaptive_ridge import HAR\n",
    "from kernel_har import KernelHAR\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from run_trials import RunTrials\n",
    "import warnings\n",
    "from train_time_plotter import TrainTimePlotter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"/Users/alexhagemeister/Downloads/csv/kin8nm.csv\")\n",
    "\n",
    "# Last column is the target\n",
    "X = data.iloc[:, :-1].values\n",
    "Y = data.iloc[:, -1].values\n",
    "\n",
    "# get the first 200 samples\n",
    "\n",
    "X = X[:200]\n",
    "Y = Y[:200]\n",
    "\n",
    "# split into training (X) and validation (X') sets\n",
    "X_train, X_prime, Y_train, Y_prime = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "har = HAR()\n",
    "har.knots = X_train\n",
    "basis_matrix = har._bases(X_train)\n",
    "\n",
    "K_har = basis_matrix @ basis_matrix.T\n",
    "\n",
    "khar = KernelHAR()\n",
    "khar.knots = X_train\n",
    "K_khar = khar._compute_kernel_matrix(X_train, X_train)\n",
    "\n",
    "# check that K_har and K_khar are the same            \n",
    "K_har - K_khar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 200, 40)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_way_bases = np.stack([\n",
    "    np.less.outer(X[:,j], X_prime[:,j])\n",
    "    for j in range(X.shape[1])\n",
    "])\n",
    "one_way_bases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 8), (40, 8))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X_prime.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 40800)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basis_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[0]* (2**(X.shape[1])-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>p</th>\n",
       "      <th>n</th>\n",
       "      <th>LTB</th>\n",
       "      <th>GBT</th>\n",
       "      <th>HAL</th>\n",
       "      <th>LASSO</th>\n",
       "      <th>HAR</th>\n",
       "      <th>KernelHAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yacht</td>\n",
       "      <td>6</td>\n",
       "      <td>308</td>\n",
       "      <td>0.90 (10.69)</td>\n",
       "      <td>0.90 (4.68)</td>\n",
       "      <td>0.72 (0.92)</td>\n",
       "      <td>8.92 (0.01)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>energy</td>\n",
       "      <td>8</td>\n",
       "      <td>768</td>\n",
       "      <td>0.40 (30.82)</td>\n",
       "      <td>0.40 (21.46)</td>\n",
       "      <td>0.43 (45.80)</td>\n",
       "      <td>4.14 (0.01)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boston</td>\n",
       "      <td>13</td>\n",
       "      <td>506</td>\n",
       "      <td>3.35 (5.92)</td>\n",
       "      <td>3.43 (4.47)</td>\n",
       "      <td>3.66 (916.61)</td>\n",
       "      <td>5.02 (0.01)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>concrete</td>\n",
       "      <td>8</td>\n",
       "      <td>1030</td>\n",
       "      <td>4.70 (43.29)</td>\n",
       "      <td>4.87 (37.15)</td>\n",
       "      <td>4.02 (134.01)</td>\n",
       "      <td>10.40 (0.01)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wine</td>\n",
       "      <td>11</td>\n",
       "      <td>1599</td>\n",
       "      <td>0.64 (6.01)</td>\n",
       "      <td>0.63 (3.58)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.67 (0.03)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>power</td>\n",
       "      <td>4</td>\n",
       "      <td>9568</td>\n",
       "      <td>3.41 (56.92)</td>\n",
       "      <td>3.46 (28.88)</td>\n",
       "      <td>–</td>\n",
       "      <td>4.59 (0.04)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kin8nm</td>\n",
       "      <td>8</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.12 (96.50)</td>\n",
       "      <td>0.10 (60.40)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.21 (0.03)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>naval</td>\n",
       "      <td>17</td>\n",
       "      <td>11934</td>\n",
       "      <td>0.00 (107.98)</td>\n",
       "      <td>0.00 (56.19)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.01 (10.51)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>protein</td>\n",
       "      <td>9</td>\n",
       "      <td>45730</td>\n",
       "      <td>1.94 (611.38)</td>\n",
       "      <td>1.94 (96.80)</td>\n",
       "      <td>–</td>\n",
       "      <td>2.50 (0.33)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>blog</td>\n",
       "      <td>280</td>\n",
       "      <td>52397</td>\n",
       "      <td>23.49 (185.49)</td>\n",
       "      <td>23.46 (9.90)</td>\n",
       "      <td>–</td>\n",
       "      <td>28.25 (13.51)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>slice</td>\n",
       "      <td>384</td>\n",
       "      <td>53500</td>\n",
       "      <td>1.23 (3350.61)</td>\n",
       "      <td>1.24 (3067.95)</td>\n",
       "      <td>–</td>\n",
       "      <td>8.33 (121.71)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>yearmsd</td>\n",
       "      <td>90</td>\n",
       "      <td>515345</td>\n",
       "      <td>8.54 (4616.82)</td>\n",
       "      <td>8.54 (1543.05)</td>\n",
       "      <td>–</td>\n",
       "      <td>9.49 (40.09)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        data    p       n             LTB             GBT            HAL  \\\n",
       "0      yacht    6     308    0.90 (10.69)     0.90 (4.68)    0.72 (0.92)   \n",
       "1     energy    8     768    0.40 (30.82)    0.40 (21.46)   0.43 (45.80)   \n",
       "2     boston   13     506     3.35 (5.92)     3.43 (4.47)  3.66 (916.61)   \n",
       "3   concrete    8    1030    4.70 (43.29)    4.87 (37.15)  4.02 (134.01)   \n",
       "4       wine   11    1599     0.64 (6.01)     0.63 (3.58)              –   \n",
       "5      power    4    9568    3.41 (56.92)    3.46 (28.88)              –   \n",
       "6     kin8nm    8    8192    0.12 (96.50)    0.10 (60.40)              –   \n",
       "7      naval   17   11934   0.00 (107.98)    0.00 (56.19)              –   \n",
       "8    protein    9   45730   1.94 (611.38)    1.94 (96.80)              –   \n",
       "9       blog  280   52397  23.49 (185.49)    23.46 (9.90)              –   \n",
       "10     slice  384   53500  1.23 (3350.61)  1.24 (3067.95)              –   \n",
       "11   yearmsd   90  515345  8.54 (4616.82)  8.54 (1543.05)              –   \n",
       "\n",
       "            LASSO HAR KernelHAR  \n",
       "0     8.92 (0.01)   –         –  \n",
       "1     4.14 (0.01)   –         –  \n",
       "2     5.02 (0.01)   –         –  \n",
       "3    10.40 (0.01)   –         –  \n",
       "4     0.67 (0.03)   –         –  \n",
       "5     4.59 (0.04)   –         –  \n",
       "6     0.21 (0.03)   –         –  \n",
       "7    0.01 (10.51)   –         –  \n",
       "8     2.50 (0.33)   –         –  \n",
       "9   28.25 (13.51)   –         –  \n",
       "10  8.33 (121.71)   –         –  \n",
       "11   9.49 (40.09)   –         –  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from tabulate import tabulate\n",
    "import time\n",
    "\n",
    "# Sample data (replace with actual data)\n",
    "data = {\n",
    "    'data': ['yacht', 'energy', 'boston', 'concrete', 'wine', 'power', 'kin8nm', 'naval', 'protein', 'blog', 'slice', 'yearmsd'],\n",
    "    'p': [6, 8, 13, 8, 11, 4, 8, 17, 9, 280, 384, 90],\n",
    "    'n': [308, 768, 506, 1030, 1599, 9568, 8192, 11934, 45730, 52397, 53500, 515345],\n",
    "    'LTB': ['0.90 (10.69)', '0.40 (30.82)', '3.35 (5.92)', '4.70 (43.29)', '0.64 (6.01)', '3.41 (56.92)', '0.12 (96.50)', '0.00 (107.98)', '1.94 (611.38)', '23.49 (185.49)', '1.23 (3350.61)', '8.54 (4616.82)'],\n",
    "    'GBT': ['0.90 (4.68)', '0.40 (21.46)', '3.43 (4.47)', '4.87 (37.15)', '0.63 (3.58)', '3.46 (28.88)', '0.10 (60.40)', '0.00 (56.19)', '1.94 (96.80)', '23.46 (9.90)', '1.24 (3067.95)', '8.54 (1543.05)'],\n",
    "    'HAL': ['0.72 (0.92)', '0.43 (45.80)', '3.66 (916.61)', '4.02 (134.01)', '–', '–', '–', '–', '–', '–', '–', '–'],\n",
    "    'LASSO': ['8.92 (0.01)', '4.14 (0.01)', '5.02 (0.01)', '10.40 (0.01)', '0.67 (0.03)', '4.59 (0.04)', '0.21 (0.03)', '0.01 (10.51)', '2.50 (0.33)', '28.25 (13.51)', '8.33 (121.71)', '9.49 (40.09)'],\n",
    "    'HAR': ['–'] * 12,  # Initialize with '-'\n",
    "    'KernelHAR': ['–'] * 12  # Initialize with '-'\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "table_df = pd.DataFrame(data)\n",
    "\n",
    "# pickle the dataframe as 'models_compare_table.pickle'\n",
    "table_file_name = \"models_compare_table.pickle\"\n",
    "df.to_pickle(table_file_name)\n",
    "\n",
    "# Display the DataFrame\n",
    "table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from IPython.display import display\n",
    "\n",
    "def update_results(df, dataset_name, method_name, rmse, training_time):\n",
    "    index = df[df['data'] == dataset_name].index[0]\n",
    "    df.at[index, method_name] = f\"{rmse:.2f} ({training_time:.2f})\"\n",
    "\n",
    "# Sample function to simulate training and testing\n",
    "def train_and_evaluate(method, X_train, Y_train, X_test, Y_test):\n",
    "    start_time = time.time()\n",
    "    method.fit(X_train, Y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    predictions = method.predict(X_test)\n",
    "    mse = mean_squared_error(Y_test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse, training_time\n",
    "\n",
    "# funtion to read data from csv file and return X and Y\n",
    "def read_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    # Check for missing values\n",
    "    if data.isnull().values.any():\n",
    "        print(\"Data contains missing values. Please handle them before training.\")\n",
    "        data = data.dropna()\n",
    "\n",
    "    # Ensure all data are numeric\n",
    "    if not all(np.issubdtype(dtype, np.number) for dtype in data.dtypes):\n",
    "        print(\"Data contains non-numeric values. Please convert them to numeric before training.\")\n",
    "\n",
    "    # Last column is the target\n",
    "    X = data.iloc[:, :-1].values\n",
    "    Y = data.iloc[:, -1].values\n",
    "    return X, Y\n",
    "\n",
    "def run_real_data_trials(dataset_name, method, num_trials=1):\n",
    "    \"\"\"\n",
    "    Run trials on a real dataset using the specified method.\n",
    "    PARAM: \n",
    "        dataset_name: str - name of the dataset \n",
    "        method: object - the method to use\n",
    "    RETURN:\n",
    "        average_rmse: float - the average RMSE over all trials\n",
    "        average_training_time: float - the average training time over all trials\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the data and split into X and Y\n",
    "    X, Y = read_data(f\"/Users/alexhagemeister/Downloads/csv/{dataset_name}.csv\")\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Run trials\n",
    "    rmses = []\n",
    "    training_times = []\n",
    "\n",
    "    for _ in range(num_trials):\n",
    "        rmse, training_time = train_and_evaluate(method, X_train, Y_train, X_test, Y_test)\n",
    "        rmses.append(rmse)\n",
    "        training_times.append(training_time)\n",
    "\n",
    "    # Calculate the average RMSE and training time\n",
    "    average_rmse = np.mean(rmses)\n",
    "    average_training_time = np.mean(training_times)\n",
    "\n",
    "    return average_rmse, average_training_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>p</th>\n",
       "      <th>n</th>\n",
       "      <th>LTB</th>\n",
       "      <th>GBT</th>\n",
       "      <th>HAL</th>\n",
       "      <th>LASSO</th>\n",
       "      <th>HAR</th>\n",
       "      <th>KernelHAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yacht</td>\n",
       "      <td>6</td>\n",
       "      <td>308</td>\n",
       "      <td>0.90 (10.69)</td>\n",
       "      <td>0.90 (4.68)</td>\n",
       "      <td>0.72 (0.92)</td>\n",
       "      <td>8.92 (0.01)</td>\n",
       "      <td>0.42 (0.49)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>energy</td>\n",
       "      <td>8</td>\n",
       "      <td>768</td>\n",
       "      <td>0.40 (30.82)</td>\n",
       "      <td>0.40 (21.46)</td>\n",
       "      <td>0.43 (45.80)</td>\n",
       "      <td>4.14 (0.01)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boston</td>\n",
       "      <td>13</td>\n",
       "      <td>506</td>\n",
       "      <td>3.35 (5.92)</td>\n",
       "      <td>3.43 (4.47)</td>\n",
       "      <td>3.66 (916.61)</td>\n",
       "      <td>5.02 (0.01)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>concrete</td>\n",
       "      <td>8</td>\n",
       "      <td>1030</td>\n",
       "      <td>4.70 (43.29)</td>\n",
       "      <td>4.87 (37.15)</td>\n",
       "      <td>4.02 (134.01)</td>\n",
       "      <td>10.40 (0.01)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wine</td>\n",
       "      <td>11</td>\n",
       "      <td>1599</td>\n",
       "      <td>0.64 (6.01)</td>\n",
       "      <td>0.63 (3.58)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.67 (0.03)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>power</td>\n",
       "      <td>4</td>\n",
       "      <td>9568</td>\n",
       "      <td>3.41 (56.92)</td>\n",
       "      <td>3.46 (28.88)</td>\n",
       "      <td>–</td>\n",
       "      <td>4.59 (0.04)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kin8nm</td>\n",
       "      <td>8</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.12 (96.50)</td>\n",
       "      <td>0.10 (60.40)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.21 (0.03)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>naval</td>\n",
       "      <td>17</td>\n",
       "      <td>11934</td>\n",
       "      <td>0.00 (107.98)</td>\n",
       "      <td>0.00 (56.19)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.01 (10.51)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>protein</td>\n",
       "      <td>9</td>\n",
       "      <td>45730</td>\n",
       "      <td>1.94 (611.38)</td>\n",
       "      <td>1.94 (96.80)</td>\n",
       "      <td>–</td>\n",
       "      <td>2.50 (0.33)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>blog</td>\n",
       "      <td>280</td>\n",
       "      <td>52397</td>\n",
       "      <td>23.49 (185.49)</td>\n",
       "      <td>23.46 (9.90)</td>\n",
       "      <td>–</td>\n",
       "      <td>28.25 (13.51)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>slice</td>\n",
       "      <td>384</td>\n",
       "      <td>53500</td>\n",
       "      <td>1.23 (3350.61)</td>\n",
       "      <td>1.24 (3067.95)</td>\n",
       "      <td>–</td>\n",
       "      <td>8.33 (121.71)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>yearmsd</td>\n",
       "      <td>90</td>\n",
       "      <td>515345</td>\n",
       "      <td>8.54 (4616.82)</td>\n",
       "      <td>8.54 (1543.05)</td>\n",
       "      <td>–</td>\n",
       "      <td>9.49 (40.09)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        data    p       n             LTB             GBT            HAL  \\\n",
       "0      yacht    6     308    0.90 (10.69)     0.90 (4.68)    0.72 (0.92)   \n",
       "1     energy    8     768    0.40 (30.82)    0.40 (21.46)   0.43 (45.80)   \n",
       "2     boston   13     506     3.35 (5.92)     3.43 (4.47)  3.66 (916.61)   \n",
       "3   concrete    8    1030    4.70 (43.29)    4.87 (37.15)  4.02 (134.01)   \n",
       "4       wine   11    1599     0.64 (6.01)     0.63 (3.58)              –   \n",
       "5      power    4    9568    3.41 (56.92)    3.46 (28.88)              –   \n",
       "6     kin8nm    8    8192    0.12 (96.50)    0.10 (60.40)              –   \n",
       "7      naval   17   11934   0.00 (107.98)    0.00 (56.19)              –   \n",
       "8    protein    9   45730   1.94 (611.38)    1.94 (96.80)              –   \n",
       "9       blog  280   52397  23.49 (185.49)    23.46 (9.90)              –   \n",
       "10     slice  384   53500  1.23 (3350.61)  1.24 (3067.95)              –   \n",
       "11   yearmsd   90  515345  8.54 (4616.82)  8.54 (1543.05)              –   \n",
       "\n",
       "            LASSO          HAR KernelHAR  \n",
       "0     8.92 (0.01)  0.42 (0.49)         –  \n",
       "1     4.14 (0.01)            –         –  \n",
       "2     5.02 (0.01)            –         –  \n",
       "3    10.40 (0.01)            –         –  \n",
       "4     0.67 (0.03)            –         –  \n",
       "5     4.59 (0.04)            –         –  \n",
       "6     0.21 (0.03)            –         –  \n",
       "7    0.01 (10.51)            –         –  \n",
       "8     2.50 (0.33)            –         –  \n",
       "9   28.25 (13.51)            –         –  \n",
       "10  8.33 (121.71)            –         –  \n",
       "11   9.49 (40.09)            –         –  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>p</th>\n",
       "      <th>n</th>\n",
       "      <th>LTB</th>\n",
       "      <th>GBT</th>\n",
       "      <th>HAL</th>\n",
       "      <th>LASSO</th>\n",
       "      <th>HAR</th>\n",
       "      <th>KernelHAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yacht</td>\n",
       "      <td>6</td>\n",
       "      <td>308</td>\n",
       "      <td>0.90 (10.69)</td>\n",
       "      <td>0.90 (4.68)</td>\n",
       "      <td>0.72 (0.92)</td>\n",
       "      <td>8.92 (0.01)</td>\n",
       "      <td>0.42 (0.49)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>energy</td>\n",
       "      <td>8</td>\n",
       "      <td>768</td>\n",
       "      <td>0.40 (30.82)</td>\n",
       "      <td>0.40 (21.46)</td>\n",
       "      <td>0.43 (45.80)</td>\n",
       "      <td>4.14 (0.01)</td>\n",
       "      <td>0.43 (1.86)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boston</td>\n",
       "      <td>13</td>\n",
       "      <td>506</td>\n",
       "      <td>3.35 (5.92)</td>\n",
       "      <td>3.43 (4.47)</td>\n",
       "      <td>3.66 (916.61)</td>\n",
       "      <td>5.02 (0.01)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>concrete</td>\n",
       "      <td>8</td>\n",
       "      <td>1030</td>\n",
       "      <td>4.70 (43.29)</td>\n",
       "      <td>4.87 (37.15)</td>\n",
       "      <td>4.02 (134.01)</td>\n",
       "      <td>10.40 (0.01)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wine</td>\n",
       "      <td>11</td>\n",
       "      <td>1599</td>\n",
       "      <td>0.64 (6.01)</td>\n",
       "      <td>0.63 (3.58)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.67 (0.03)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>power</td>\n",
       "      <td>4</td>\n",
       "      <td>9568</td>\n",
       "      <td>3.41 (56.92)</td>\n",
       "      <td>3.46 (28.88)</td>\n",
       "      <td>–</td>\n",
       "      <td>4.59 (0.04)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kin8nm</td>\n",
       "      <td>8</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.12 (96.50)</td>\n",
       "      <td>0.10 (60.40)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.21 (0.03)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>naval</td>\n",
       "      <td>17</td>\n",
       "      <td>11934</td>\n",
       "      <td>0.00 (107.98)</td>\n",
       "      <td>0.00 (56.19)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.01 (10.51)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>protein</td>\n",
       "      <td>9</td>\n",
       "      <td>45730</td>\n",
       "      <td>1.94 (611.38)</td>\n",
       "      <td>1.94 (96.80)</td>\n",
       "      <td>–</td>\n",
       "      <td>2.50 (0.33)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>blog</td>\n",
       "      <td>280</td>\n",
       "      <td>52397</td>\n",
       "      <td>23.49 (185.49)</td>\n",
       "      <td>23.46 (9.90)</td>\n",
       "      <td>–</td>\n",
       "      <td>28.25 (13.51)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>slice</td>\n",
       "      <td>384</td>\n",
       "      <td>53500</td>\n",
       "      <td>1.23 (3350.61)</td>\n",
       "      <td>1.24 (3067.95)</td>\n",
       "      <td>–</td>\n",
       "      <td>8.33 (121.71)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>yearmsd</td>\n",
       "      <td>90</td>\n",
       "      <td>515345</td>\n",
       "      <td>8.54 (4616.82)</td>\n",
       "      <td>8.54 (1543.05)</td>\n",
       "      <td>–</td>\n",
       "      <td>9.49 (40.09)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        data    p       n             LTB             GBT            HAL  \\\n",
       "0      yacht    6     308    0.90 (10.69)     0.90 (4.68)    0.72 (0.92)   \n",
       "1     energy    8     768    0.40 (30.82)    0.40 (21.46)   0.43 (45.80)   \n",
       "2     boston   13     506     3.35 (5.92)     3.43 (4.47)  3.66 (916.61)   \n",
       "3   concrete    8    1030    4.70 (43.29)    4.87 (37.15)  4.02 (134.01)   \n",
       "4       wine   11    1599     0.64 (6.01)     0.63 (3.58)              –   \n",
       "5      power    4    9568    3.41 (56.92)    3.46 (28.88)              –   \n",
       "6     kin8nm    8    8192    0.12 (96.50)    0.10 (60.40)              –   \n",
       "7      naval   17   11934   0.00 (107.98)    0.00 (56.19)              –   \n",
       "8    protein    9   45730   1.94 (611.38)    1.94 (96.80)              –   \n",
       "9       blog  280   52397  23.49 (185.49)    23.46 (9.90)              –   \n",
       "10     slice  384   53500  1.23 (3350.61)  1.24 (3067.95)              –   \n",
       "11   yearmsd   90  515345  8.54 (4616.82)  8.54 (1543.05)              –   \n",
       "\n",
       "            LASSO          HAR KernelHAR  \n",
       "0     8.92 (0.01)  0.42 (0.49)         –  \n",
       "1     4.14 (0.01)  0.43 (1.86)         –  \n",
       "2     5.02 (0.01)            –         –  \n",
       "3    10.40 (0.01)            –         –  \n",
       "4     0.67 (0.03)            –         –  \n",
       "5     4.59 (0.04)            –         –  \n",
       "6     0.21 (0.03)            –         –  \n",
       "7    0.01 (10.51)            –         –  \n",
       "8     2.50 (0.33)            –         –  \n",
       "9   28.25 (13.51)            –         –  \n",
       "10  8.33 (121.71)            –         –  \n",
       "11   9.49 (40.09)            –         –  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>p</th>\n",
       "      <th>n</th>\n",
       "      <th>LTB</th>\n",
       "      <th>GBT</th>\n",
       "      <th>HAL</th>\n",
       "      <th>LASSO</th>\n",
       "      <th>HAR</th>\n",
       "      <th>KernelHAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yacht</td>\n",
       "      <td>6</td>\n",
       "      <td>308</td>\n",
       "      <td>0.90 (10.69)</td>\n",
       "      <td>0.90 (4.68)</td>\n",
       "      <td>0.72 (0.92)</td>\n",
       "      <td>8.92 (0.01)</td>\n",
       "      <td>0.42 (0.49)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>energy</td>\n",
       "      <td>8</td>\n",
       "      <td>768</td>\n",
       "      <td>0.40 (30.82)</td>\n",
       "      <td>0.40 (21.46)</td>\n",
       "      <td>0.43 (45.80)</td>\n",
       "      <td>4.14 (0.01)</td>\n",
       "      <td>0.43 (1.86)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boston</td>\n",
       "      <td>13</td>\n",
       "      <td>506</td>\n",
       "      <td>3.35 (5.92)</td>\n",
       "      <td>3.43 (4.47)</td>\n",
       "      <td>3.66 (916.61)</td>\n",
       "      <td>5.02 (0.01)</td>\n",
       "      <td>3.79 (49.22)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>concrete</td>\n",
       "      <td>8</td>\n",
       "      <td>1030</td>\n",
       "      <td>4.70 (43.29)</td>\n",
       "      <td>4.87 (37.15)</td>\n",
       "      <td>4.02 (134.01)</td>\n",
       "      <td>10.40 (0.01)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wine</td>\n",
       "      <td>11</td>\n",
       "      <td>1599</td>\n",
       "      <td>0.64 (6.01)</td>\n",
       "      <td>0.63 (3.58)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.67 (0.03)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>power</td>\n",
       "      <td>4</td>\n",
       "      <td>9568</td>\n",
       "      <td>3.41 (56.92)</td>\n",
       "      <td>3.46 (28.88)</td>\n",
       "      <td>–</td>\n",
       "      <td>4.59 (0.04)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kin8nm</td>\n",
       "      <td>8</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.12 (96.50)</td>\n",
       "      <td>0.10 (60.40)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.21 (0.03)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>naval</td>\n",
       "      <td>17</td>\n",
       "      <td>11934</td>\n",
       "      <td>0.00 (107.98)</td>\n",
       "      <td>0.00 (56.19)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.01 (10.51)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>protein</td>\n",
       "      <td>9</td>\n",
       "      <td>45730</td>\n",
       "      <td>1.94 (611.38)</td>\n",
       "      <td>1.94 (96.80)</td>\n",
       "      <td>–</td>\n",
       "      <td>2.50 (0.33)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>blog</td>\n",
       "      <td>280</td>\n",
       "      <td>52397</td>\n",
       "      <td>23.49 (185.49)</td>\n",
       "      <td>23.46 (9.90)</td>\n",
       "      <td>–</td>\n",
       "      <td>28.25 (13.51)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>slice</td>\n",
       "      <td>384</td>\n",
       "      <td>53500</td>\n",
       "      <td>1.23 (3350.61)</td>\n",
       "      <td>1.24 (3067.95)</td>\n",
       "      <td>–</td>\n",
       "      <td>8.33 (121.71)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>yearmsd</td>\n",
       "      <td>90</td>\n",
       "      <td>515345</td>\n",
       "      <td>8.54 (4616.82)</td>\n",
       "      <td>8.54 (1543.05)</td>\n",
       "      <td>–</td>\n",
       "      <td>9.49 (40.09)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        data    p       n             LTB             GBT            HAL  \\\n",
       "0      yacht    6     308    0.90 (10.69)     0.90 (4.68)    0.72 (0.92)   \n",
       "1     energy    8     768    0.40 (30.82)    0.40 (21.46)   0.43 (45.80)   \n",
       "2     boston   13     506     3.35 (5.92)     3.43 (4.47)  3.66 (916.61)   \n",
       "3   concrete    8    1030    4.70 (43.29)    4.87 (37.15)  4.02 (134.01)   \n",
       "4       wine   11    1599     0.64 (6.01)     0.63 (3.58)              –   \n",
       "5      power    4    9568    3.41 (56.92)    3.46 (28.88)              –   \n",
       "6     kin8nm    8    8192    0.12 (96.50)    0.10 (60.40)              –   \n",
       "7      naval   17   11934   0.00 (107.98)    0.00 (56.19)              –   \n",
       "8    protein    9   45730   1.94 (611.38)    1.94 (96.80)              –   \n",
       "9       blog  280   52397  23.49 (185.49)    23.46 (9.90)              –   \n",
       "10     slice  384   53500  1.23 (3350.61)  1.24 (3067.95)              –   \n",
       "11   yearmsd   90  515345  8.54 (4616.82)  8.54 (1543.05)              –   \n",
       "\n",
       "            LASSO           HAR KernelHAR  \n",
       "0     8.92 (0.01)   0.42 (0.49)         –  \n",
       "1     4.14 (0.01)   0.43 (1.86)         –  \n",
       "2     5.02 (0.01)  3.79 (49.22)         –  \n",
       "3    10.40 (0.01)             –         –  \n",
       "4     0.67 (0.03)             –         –  \n",
       "5     4.59 (0.04)             –         –  \n",
       "6     0.21 (0.03)             –         –  \n",
       "7    0.01 (10.51)             –         –  \n",
       "8     2.50 (0.33)             –         –  \n",
       "9   28.25 (13.51)             –         –  \n",
       "10  8.33 (121.71)             –         –  \n",
       "11   9.49 (40.09)             –         –  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>p</th>\n",
       "      <th>n</th>\n",
       "      <th>LTB</th>\n",
       "      <th>GBT</th>\n",
       "      <th>HAL</th>\n",
       "      <th>LASSO</th>\n",
       "      <th>HAR</th>\n",
       "      <th>KernelHAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yacht</td>\n",
       "      <td>6</td>\n",
       "      <td>308</td>\n",
       "      <td>0.90 (10.69)</td>\n",
       "      <td>0.90 (4.68)</td>\n",
       "      <td>0.72 (0.92)</td>\n",
       "      <td>8.92 (0.01)</td>\n",
       "      <td>0.42 (0.49)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>energy</td>\n",
       "      <td>8</td>\n",
       "      <td>768</td>\n",
       "      <td>0.40 (30.82)</td>\n",
       "      <td>0.40 (21.46)</td>\n",
       "      <td>0.43 (45.80)</td>\n",
       "      <td>4.14 (0.01)</td>\n",
       "      <td>0.43 (1.86)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boston</td>\n",
       "      <td>13</td>\n",
       "      <td>506</td>\n",
       "      <td>3.35 (5.92)</td>\n",
       "      <td>3.43 (4.47)</td>\n",
       "      <td>3.66 (916.61)</td>\n",
       "      <td>5.02 (0.01)</td>\n",
       "      <td>3.79 (49.22)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>concrete</td>\n",
       "      <td>8</td>\n",
       "      <td>1030</td>\n",
       "      <td>4.70 (43.29)</td>\n",
       "      <td>4.87 (37.15)</td>\n",
       "      <td>4.02 (134.01)</td>\n",
       "      <td>10.40 (0.01)</td>\n",
       "      <td>3.96 (3.69)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wine</td>\n",
       "      <td>11</td>\n",
       "      <td>1599</td>\n",
       "      <td>0.64 (6.01)</td>\n",
       "      <td>0.63 (3.58)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.67 (0.03)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>power</td>\n",
       "      <td>4</td>\n",
       "      <td>9568</td>\n",
       "      <td>3.41 (56.92)</td>\n",
       "      <td>3.46 (28.88)</td>\n",
       "      <td>–</td>\n",
       "      <td>4.59 (0.04)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kin8nm</td>\n",
       "      <td>8</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.12 (96.50)</td>\n",
       "      <td>0.10 (60.40)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.21 (0.03)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>naval</td>\n",
       "      <td>17</td>\n",
       "      <td>11934</td>\n",
       "      <td>0.00 (107.98)</td>\n",
       "      <td>0.00 (56.19)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.01 (10.51)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>protein</td>\n",
       "      <td>9</td>\n",
       "      <td>45730</td>\n",
       "      <td>1.94 (611.38)</td>\n",
       "      <td>1.94 (96.80)</td>\n",
       "      <td>–</td>\n",
       "      <td>2.50 (0.33)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>blog</td>\n",
       "      <td>280</td>\n",
       "      <td>52397</td>\n",
       "      <td>23.49 (185.49)</td>\n",
       "      <td>23.46 (9.90)</td>\n",
       "      <td>–</td>\n",
       "      <td>28.25 (13.51)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>slice</td>\n",
       "      <td>384</td>\n",
       "      <td>53500</td>\n",
       "      <td>1.23 (3350.61)</td>\n",
       "      <td>1.24 (3067.95)</td>\n",
       "      <td>–</td>\n",
       "      <td>8.33 (121.71)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>yearmsd</td>\n",
       "      <td>90</td>\n",
       "      <td>515345</td>\n",
       "      <td>8.54 (4616.82)</td>\n",
       "      <td>8.54 (1543.05)</td>\n",
       "      <td>–</td>\n",
       "      <td>9.49 (40.09)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        data    p       n             LTB             GBT            HAL  \\\n",
       "0      yacht    6     308    0.90 (10.69)     0.90 (4.68)    0.72 (0.92)   \n",
       "1     energy    8     768    0.40 (30.82)    0.40 (21.46)   0.43 (45.80)   \n",
       "2     boston   13     506     3.35 (5.92)     3.43 (4.47)  3.66 (916.61)   \n",
       "3   concrete    8    1030    4.70 (43.29)    4.87 (37.15)  4.02 (134.01)   \n",
       "4       wine   11    1599     0.64 (6.01)     0.63 (3.58)              –   \n",
       "5      power    4    9568    3.41 (56.92)    3.46 (28.88)              –   \n",
       "6     kin8nm    8    8192    0.12 (96.50)    0.10 (60.40)              –   \n",
       "7      naval   17   11934   0.00 (107.98)    0.00 (56.19)              –   \n",
       "8    protein    9   45730   1.94 (611.38)    1.94 (96.80)              –   \n",
       "9       blog  280   52397  23.49 (185.49)    23.46 (9.90)              –   \n",
       "10     slice  384   53500  1.23 (3350.61)  1.24 (3067.95)              –   \n",
       "11   yearmsd   90  515345  8.54 (4616.82)  8.54 (1543.05)              –   \n",
       "\n",
       "            LASSO           HAR KernelHAR  \n",
       "0     8.92 (0.01)   0.42 (0.49)         –  \n",
       "1     4.14 (0.01)   0.43 (1.86)         –  \n",
       "2     5.02 (0.01)  3.79 (49.22)         –  \n",
       "3    10.40 (0.01)   3.96 (3.69)         –  \n",
       "4     0.67 (0.03)             –         –  \n",
       "5     4.59 (0.04)             –         –  \n",
       "6     0.21 (0.03)             –         –  \n",
       "7    0.01 (10.51)             –         –  \n",
       "8     2.50 (0.33)             –         –  \n",
       "9   28.25 (13.51)             –         –  \n",
       "10  8.33 (121.71)             –         –  \n",
       "11   9.49 (40.09)             –         –  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>p</th>\n",
       "      <th>n</th>\n",
       "      <th>LTB</th>\n",
       "      <th>GBT</th>\n",
       "      <th>HAL</th>\n",
       "      <th>LASSO</th>\n",
       "      <th>HAR</th>\n",
       "      <th>KernelHAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yacht</td>\n",
       "      <td>6</td>\n",
       "      <td>308</td>\n",
       "      <td>0.90 (10.69)</td>\n",
       "      <td>0.90 (4.68)</td>\n",
       "      <td>0.72 (0.92)</td>\n",
       "      <td>8.92 (0.01)</td>\n",
       "      <td>0.42 (0.49)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>energy</td>\n",
       "      <td>8</td>\n",
       "      <td>768</td>\n",
       "      <td>0.40 (30.82)</td>\n",
       "      <td>0.40 (21.46)</td>\n",
       "      <td>0.43 (45.80)</td>\n",
       "      <td>4.14 (0.01)</td>\n",
       "      <td>0.43 (1.86)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boston</td>\n",
       "      <td>13</td>\n",
       "      <td>506</td>\n",
       "      <td>3.35 (5.92)</td>\n",
       "      <td>3.43 (4.47)</td>\n",
       "      <td>3.66 (916.61)</td>\n",
       "      <td>5.02 (0.01)</td>\n",
       "      <td>3.79 (49.22)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>concrete</td>\n",
       "      <td>8</td>\n",
       "      <td>1030</td>\n",
       "      <td>4.70 (43.29)</td>\n",
       "      <td>4.87 (37.15)</td>\n",
       "      <td>4.02 (134.01)</td>\n",
       "      <td>10.40 (0.01)</td>\n",
       "      <td>3.96 (3.69)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wine</td>\n",
       "      <td>11</td>\n",
       "      <td>1599</td>\n",
       "      <td>0.64 (6.01)</td>\n",
       "      <td>0.63 (3.58)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.67 (0.03)</td>\n",
       "      <td>0.59 (107.46)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>power</td>\n",
       "      <td>4</td>\n",
       "      <td>9568</td>\n",
       "      <td>3.41 (56.92)</td>\n",
       "      <td>3.46 (28.88)</td>\n",
       "      <td>–</td>\n",
       "      <td>4.59 (0.04)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kin8nm</td>\n",
       "      <td>8</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.12 (96.50)</td>\n",
       "      <td>0.10 (60.40)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.21 (0.03)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>naval</td>\n",
       "      <td>17</td>\n",
       "      <td>11934</td>\n",
       "      <td>0.00 (107.98)</td>\n",
       "      <td>0.00 (56.19)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.01 (10.51)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>protein</td>\n",
       "      <td>9</td>\n",
       "      <td>45730</td>\n",
       "      <td>1.94 (611.38)</td>\n",
       "      <td>1.94 (96.80)</td>\n",
       "      <td>–</td>\n",
       "      <td>2.50 (0.33)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>blog</td>\n",
       "      <td>280</td>\n",
       "      <td>52397</td>\n",
       "      <td>23.49 (185.49)</td>\n",
       "      <td>23.46 (9.90)</td>\n",
       "      <td>–</td>\n",
       "      <td>28.25 (13.51)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>slice</td>\n",
       "      <td>384</td>\n",
       "      <td>53500</td>\n",
       "      <td>1.23 (3350.61)</td>\n",
       "      <td>1.24 (3067.95)</td>\n",
       "      <td>–</td>\n",
       "      <td>8.33 (121.71)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>yearmsd</td>\n",
       "      <td>90</td>\n",
       "      <td>515345</td>\n",
       "      <td>8.54 (4616.82)</td>\n",
       "      <td>8.54 (1543.05)</td>\n",
       "      <td>–</td>\n",
       "      <td>9.49 (40.09)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        data    p       n             LTB             GBT            HAL  \\\n",
       "0      yacht    6     308    0.90 (10.69)     0.90 (4.68)    0.72 (0.92)   \n",
       "1     energy    8     768    0.40 (30.82)    0.40 (21.46)   0.43 (45.80)   \n",
       "2     boston   13     506     3.35 (5.92)     3.43 (4.47)  3.66 (916.61)   \n",
       "3   concrete    8    1030    4.70 (43.29)    4.87 (37.15)  4.02 (134.01)   \n",
       "4       wine   11    1599     0.64 (6.01)     0.63 (3.58)              –   \n",
       "5      power    4    9568    3.41 (56.92)    3.46 (28.88)              –   \n",
       "6     kin8nm    8    8192    0.12 (96.50)    0.10 (60.40)              –   \n",
       "7      naval   17   11934   0.00 (107.98)    0.00 (56.19)              –   \n",
       "8    protein    9   45730   1.94 (611.38)    1.94 (96.80)              –   \n",
       "9       blog  280   52397  23.49 (185.49)    23.46 (9.90)              –   \n",
       "10     slice  384   53500  1.23 (3350.61)  1.24 (3067.95)              –   \n",
       "11   yearmsd   90  515345  8.54 (4616.82)  8.54 (1543.05)              –   \n",
       "\n",
       "            LASSO            HAR KernelHAR  \n",
       "0     8.92 (0.01)    0.42 (0.49)         –  \n",
       "1     4.14 (0.01)    0.43 (1.86)         –  \n",
       "2     5.02 (0.01)   3.79 (49.22)         –  \n",
       "3    10.40 (0.01)    3.96 (3.69)         –  \n",
       "4     0.67 (0.03)  0.59 (107.46)         –  \n",
       "5     4.59 (0.04)              –         –  \n",
       "6     0.21 (0.03)              –         –  \n",
       "7    0.01 (10.51)              –         –  \n",
       "8     2.50 (0.33)              –         –  \n",
       "9   28.25 (13.51)              –         –  \n",
       "10  8.33 (121.71)              –         –  \n",
       "11   9.49 (40.09)              –         –  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>p</th>\n",
       "      <th>n</th>\n",
       "      <th>LTB</th>\n",
       "      <th>GBT</th>\n",
       "      <th>HAL</th>\n",
       "      <th>LASSO</th>\n",
       "      <th>HAR</th>\n",
       "      <th>KernelHAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yacht</td>\n",
       "      <td>6</td>\n",
       "      <td>308</td>\n",
       "      <td>0.90 (10.69)</td>\n",
       "      <td>0.90 (4.68)</td>\n",
       "      <td>0.72 (0.92)</td>\n",
       "      <td>8.92 (0.01)</td>\n",
       "      <td>0.42 (0.49)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>energy</td>\n",
       "      <td>8</td>\n",
       "      <td>768</td>\n",
       "      <td>0.40 (30.82)</td>\n",
       "      <td>0.40 (21.46)</td>\n",
       "      <td>0.43 (45.80)</td>\n",
       "      <td>4.14 (0.01)</td>\n",
       "      <td>0.43 (1.86)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boston</td>\n",
       "      <td>13</td>\n",
       "      <td>506</td>\n",
       "      <td>3.35 (5.92)</td>\n",
       "      <td>3.43 (4.47)</td>\n",
       "      <td>3.66 (916.61)</td>\n",
       "      <td>5.02 (0.01)</td>\n",
       "      <td>3.79 (49.22)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>concrete</td>\n",
       "      <td>8</td>\n",
       "      <td>1030</td>\n",
       "      <td>4.70 (43.29)</td>\n",
       "      <td>4.87 (37.15)</td>\n",
       "      <td>4.02 (134.01)</td>\n",
       "      <td>10.40 (0.01)</td>\n",
       "      <td>3.96 (3.69)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wine</td>\n",
       "      <td>11</td>\n",
       "      <td>1599</td>\n",
       "      <td>0.64 (6.01)</td>\n",
       "      <td>0.63 (3.58)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.67 (0.03)</td>\n",
       "      <td>0.59 (107.46)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>power</td>\n",
       "      <td>4</td>\n",
       "      <td>9568</td>\n",
       "      <td>3.41 (56.92)</td>\n",
       "      <td>3.46 (28.88)</td>\n",
       "      <td>–</td>\n",
       "      <td>4.59 (0.04)</td>\n",
       "      <td>3.34 (83.11)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kin8nm</td>\n",
       "      <td>8</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.12 (96.50)</td>\n",
       "      <td>0.10 (60.40)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.21 (0.03)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>naval</td>\n",
       "      <td>17</td>\n",
       "      <td>11934</td>\n",
       "      <td>0.00 (107.98)</td>\n",
       "      <td>0.00 (56.19)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.01 (10.51)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>protein</td>\n",
       "      <td>9</td>\n",
       "      <td>45730</td>\n",
       "      <td>1.94 (611.38)</td>\n",
       "      <td>1.94 (96.80)</td>\n",
       "      <td>–</td>\n",
       "      <td>2.50 (0.33)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>blog</td>\n",
       "      <td>280</td>\n",
       "      <td>52397</td>\n",
       "      <td>23.49 (185.49)</td>\n",
       "      <td>23.46 (9.90)</td>\n",
       "      <td>–</td>\n",
       "      <td>28.25 (13.51)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>slice</td>\n",
       "      <td>384</td>\n",
       "      <td>53500</td>\n",
       "      <td>1.23 (3350.61)</td>\n",
       "      <td>1.24 (3067.95)</td>\n",
       "      <td>–</td>\n",
       "      <td>8.33 (121.71)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>yearmsd</td>\n",
       "      <td>90</td>\n",
       "      <td>515345</td>\n",
       "      <td>8.54 (4616.82)</td>\n",
       "      <td>8.54 (1543.05)</td>\n",
       "      <td>–</td>\n",
       "      <td>9.49 (40.09)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        data    p       n             LTB             GBT            HAL  \\\n",
       "0      yacht    6     308    0.90 (10.69)     0.90 (4.68)    0.72 (0.92)   \n",
       "1     energy    8     768    0.40 (30.82)    0.40 (21.46)   0.43 (45.80)   \n",
       "2     boston   13     506     3.35 (5.92)     3.43 (4.47)  3.66 (916.61)   \n",
       "3   concrete    8    1030    4.70 (43.29)    4.87 (37.15)  4.02 (134.01)   \n",
       "4       wine   11    1599     0.64 (6.01)     0.63 (3.58)              –   \n",
       "5      power    4    9568    3.41 (56.92)    3.46 (28.88)              –   \n",
       "6     kin8nm    8    8192    0.12 (96.50)    0.10 (60.40)              –   \n",
       "7      naval   17   11934   0.00 (107.98)    0.00 (56.19)              –   \n",
       "8    protein    9   45730   1.94 (611.38)    1.94 (96.80)              –   \n",
       "9       blog  280   52397  23.49 (185.49)    23.46 (9.90)              –   \n",
       "10     slice  384   53500  1.23 (3350.61)  1.24 (3067.95)              –   \n",
       "11   yearmsd   90  515345  8.54 (4616.82)  8.54 (1543.05)              –   \n",
       "\n",
       "            LASSO            HAR KernelHAR  \n",
       "0     8.92 (0.01)    0.42 (0.49)         –  \n",
       "1     4.14 (0.01)    0.43 (1.86)         –  \n",
       "2     5.02 (0.01)   3.79 (49.22)         –  \n",
       "3    10.40 (0.01)    3.96 (3.69)         –  \n",
       "4     0.67 (0.03)  0.59 (107.46)         –  \n",
       "5     4.59 (0.04)   3.34 (83.11)         –  \n",
       "6     0.21 (0.03)              –         –  \n",
       "7    0.01 (10.51)              –         –  \n",
       "8     2.50 (0.33)              –         –  \n",
       "9   28.25 (13.51)              –         –  \n",
       "10  8.33 (121.71)              –         –  \n",
       "11   9.49 (40.09)              –         –  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from highly_adaptive_lasso import HAL\n",
    "from highly_adaptive_ridge import HAR\n",
    "from kernel_har import KernelHAR\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import time\n",
    "import multiprocessing\n",
    "import os\n",
    "\n",
    "table_file_name = \"models_compare_table.pickle\"\n",
    "table_df = pd.read_pickle(table_file_name)\n",
    "\n",
    "for dataset_name in table_df['data']:\n",
    "    method = HAR()\n",
    "    rmse, training_time = run_real_data_trials(dataset_name, method)\n",
    "    update_results(table_df, dataset_name, method.name, rmse, training_time)\n",
    "\n",
    "    # Save the updated DataFrame\n",
    "    table_df.to_pickle(table_file_name)\n",
    "\n",
    "    # Display the updated DataFrame\n",
    "    display(table_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>p</th>\n",
       "      <th>n</th>\n",
       "      <th>LTB</th>\n",
       "      <th>GBT</th>\n",
       "      <th>HAL</th>\n",
       "      <th>LASSO</th>\n",
       "      <th>HAR</th>\n",
       "      <th>KernelHAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yacht</td>\n",
       "      <td>6</td>\n",
       "      <td>308</td>\n",
       "      <td>0.90 (10.69)</td>\n",
       "      <td>0.90 (4.68)</td>\n",
       "      <td>0.72 (0.92)</td>\n",
       "      <td>8.92 (0.01)</td>\n",
       "      <td>0.42 (0.49)</td>\n",
       "      <td>0.30 (9.80)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>energy</td>\n",
       "      <td>8</td>\n",
       "      <td>768</td>\n",
       "      <td>0.40 (30.82)</td>\n",
       "      <td>0.40 (21.46)</td>\n",
       "      <td>0.43 (45.80)</td>\n",
       "      <td>4.14 (0.01)</td>\n",
       "      <td>0.43 (1.86)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boston</td>\n",
       "      <td>13</td>\n",
       "      <td>506</td>\n",
       "      <td>3.35 (5.92)</td>\n",
       "      <td>3.43 (4.47)</td>\n",
       "      <td>3.66 (916.61)</td>\n",
       "      <td>5.02 (0.01)</td>\n",
       "      <td>3.79 (49.22)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>concrete</td>\n",
       "      <td>8</td>\n",
       "      <td>1030</td>\n",
       "      <td>4.70 (43.29)</td>\n",
       "      <td>4.87 (37.15)</td>\n",
       "      <td>4.02 (134.01)</td>\n",
       "      <td>10.40 (0.01)</td>\n",
       "      <td>3.96 (3.69)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wine</td>\n",
       "      <td>11</td>\n",
       "      <td>1599</td>\n",
       "      <td>0.64 (6.01)</td>\n",
       "      <td>0.63 (3.58)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.67 (0.03)</td>\n",
       "      <td>0.59 (107.46)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>power</td>\n",
       "      <td>4</td>\n",
       "      <td>9568</td>\n",
       "      <td>3.41 (56.92)</td>\n",
       "      <td>3.46 (28.88)</td>\n",
       "      <td>–</td>\n",
       "      <td>4.59 (0.04)</td>\n",
       "      <td>3.34 (83.11)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kin8nm</td>\n",
       "      <td>8</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.12 (96.50)</td>\n",
       "      <td>0.10 (60.40)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.21 (0.03)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>naval</td>\n",
       "      <td>17</td>\n",
       "      <td>11934</td>\n",
       "      <td>0.00 (107.98)</td>\n",
       "      <td>0.00 (56.19)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.01 (10.51)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>protein</td>\n",
       "      <td>9</td>\n",
       "      <td>45730</td>\n",
       "      <td>1.94 (611.38)</td>\n",
       "      <td>1.94 (96.80)</td>\n",
       "      <td>–</td>\n",
       "      <td>2.50 (0.33)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>blog</td>\n",
       "      <td>280</td>\n",
       "      <td>52397</td>\n",
       "      <td>23.49 (185.49)</td>\n",
       "      <td>23.46 (9.90)</td>\n",
       "      <td>–</td>\n",
       "      <td>28.25 (13.51)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>slice</td>\n",
       "      <td>384</td>\n",
       "      <td>53500</td>\n",
       "      <td>1.23 (3350.61)</td>\n",
       "      <td>1.24 (3067.95)</td>\n",
       "      <td>–</td>\n",
       "      <td>8.33 (121.71)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>yearmsd</td>\n",
       "      <td>90</td>\n",
       "      <td>515345</td>\n",
       "      <td>8.54 (4616.82)</td>\n",
       "      <td>8.54 (1543.05)</td>\n",
       "      <td>–</td>\n",
       "      <td>9.49 (40.09)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        data    p       n             LTB             GBT            HAL  \\\n",
       "0      yacht    6     308    0.90 (10.69)     0.90 (4.68)    0.72 (0.92)   \n",
       "1     energy    8     768    0.40 (30.82)    0.40 (21.46)   0.43 (45.80)   \n",
       "2     boston   13     506     3.35 (5.92)     3.43 (4.47)  3.66 (916.61)   \n",
       "3   concrete    8    1030    4.70 (43.29)    4.87 (37.15)  4.02 (134.01)   \n",
       "4       wine   11    1599     0.64 (6.01)     0.63 (3.58)              –   \n",
       "5      power    4    9568    3.41 (56.92)    3.46 (28.88)              –   \n",
       "6     kin8nm    8    8192    0.12 (96.50)    0.10 (60.40)              –   \n",
       "7      naval   17   11934   0.00 (107.98)    0.00 (56.19)              –   \n",
       "8    protein    9   45730   1.94 (611.38)    1.94 (96.80)              –   \n",
       "9       blog  280   52397  23.49 (185.49)    23.46 (9.90)              –   \n",
       "10     slice  384   53500  1.23 (3350.61)  1.24 (3067.95)              –   \n",
       "11   yearmsd   90  515345  8.54 (4616.82)  8.54 (1543.05)              –   \n",
       "\n",
       "            LASSO            HAR    KernelHAR  \n",
       "0     8.92 (0.01)    0.42 (0.49)  0.30 (9.80)  \n",
       "1     4.14 (0.01)    0.43 (1.86)            –  \n",
       "2     5.02 (0.01)   3.79 (49.22)            –  \n",
       "3    10.40 (0.01)    3.96 (3.69)            –  \n",
       "4     0.67 (0.03)  0.59 (107.46)            –  \n",
       "5     4.59 (0.04)   3.34 (83.11)            –  \n",
       "6     0.21 (0.03)              –            –  \n",
       "7    0.01 (10.51)              –            –  \n",
       "8     2.50 (0.33)              –            –  \n",
       "9   28.25 (13.51)              –            –  \n",
       "10  8.33 (121.71)              –            –  \n",
       "11   9.49 (40.09)              –            –  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>p</th>\n",
       "      <th>n</th>\n",
       "      <th>LTB</th>\n",
       "      <th>GBT</th>\n",
       "      <th>HAL</th>\n",
       "      <th>LASSO</th>\n",
       "      <th>HAR</th>\n",
       "      <th>KernelHAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yacht</td>\n",
       "      <td>6</td>\n",
       "      <td>308</td>\n",
       "      <td>0.90 (10.69)</td>\n",
       "      <td>0.90 (4.68)</td>\n",
       "      <td>0.72 (0.92)</td>\n",
       "      <td>8.92 (0.01)</td>\n",
       "      <td>0.42 (0.49)</td>\n",
       "      <td>0.30 (9.80)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>energy</td>\n",
       "      <td>8</td>\n",
       "      <td>768</td>\n",
       "      <td>0.40 (30.82)</td>\n",
       "      <td>0.40 (21.46)</td>\n",
       "      <td>0.43 (45.80)</td>\n",
       "      <td>4.14 (0.01)</td>\n",
       "      <td>0.43 (1.86)</td>\n",
       "      <td>0.39 (30.21)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boston</td>\n",
       "      <td>13</td>\n",
       "      <td>506</td>\n",
       "      <td>3.35 (5.92)</td>\n",
       "      <td>3.43 (4.47)</td>\n",
       "      <td>3.66 (916.61)</td>\n",
       "      <td>5.02 (0.01)</td>\n",
       "      <td>3.79 (49.22)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>concrete</td>\n",
       "      <td>8</td>\n",
       "      <td>1030</td>\n",
       "      <td>4.70 (43.29)</td>\n",
       "      <td>4.87 (37.15)</td>\n",
       "      <td>4.02 (134.01)</td>\n",
       "      <td>10.40 (0.01)</td>\n",
       "      <td>3.96 (3.69)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wine</td>\n",
       "      <td>11</td>\n",
       "      <td>1599</td>\n",
       "      <td>0.64 (6.01)</td>\n",
       "      <td>0.63 (3.58)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.67 (0.03)</td>\n",
       "      <td>0.59 (107.46)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>power</td>\n",
       "      <td>4</td>\n",
       "      <td>9568</td>\n",
       "      <td>3.41 (56.92)</td>\n",
       "      <td>3.46 (28.88)</td>\n",
       "      <td>–</td>\n",
       "      <td>4.59 (0.04)</td>\n",
       "      <td>3.34 (83.11)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kin8nm</td>\n",
       "      <td>8</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.12 (96.50)</td>\n",
       "      <td>0.10 (60.40)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.21 (0.03)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>naval</td>\n",
       "      <td>17</td>\n",
       "      <td>11934</td>\n",
       "      <td>0.00 (107.98)</td>\n",
       "      <td>0.00 (56.19)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.01 (10.51)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>protein</td>\n",
       "      <td>9</td>\n",
       "      <td>45730</td>\n",
       "      <td>1.94 (611.38)</td>\n",
       "      <td>1.94 (96.80)</td>\n",
       "      <td>–</td>\n",
       "      <td>2.50 (0.33)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>blog</td>\n",
       "      <td>280</td>\n",
       "      <td>52397</td>\n",
       "      <td>23.49 (185.49)</td>\n",
       "      <td>23.46 (9.90)</td>\n",
       "      <td>–</td>\n",
       "      <td>28.25 (13.51)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>slice</td>\n",
       "      <td>384</td>\n",
       "      <td>53500</td>\n",
       "      <td>1.23 (3350.61)</td>\n",
       "      <td>1.24 (3067.95)</td>\n",
       "      <td>–</td>\n",
       "      <td>8.33 (121.71)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>yearmsd</td>\n",
       "      <td>90</td>\n",
       "      <td>515345</td>\n",
       "      <td>8.54 (4616.82)</td>\n",
       "      <td>8.54 (1543.05)</td>\n",
       "      <td>–</td>\n",
       "      <td>9.49 (40.09)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        data    p       n             LTB             GBT            HAL  \\\n",
       "0      yacht    6     308    0.90 (10.69)     0.90 (4.68)    0.72 (0.92)   \n",
       "1     energy    8     768    0.40 (30.82)    0.40 (21.46)   0.43 (45.80)   \n",
       "2     boston   13     506     3.35 (5.92)     3.43 (4.47)  3.66 (916.61)   \n",
       "3   concrete    8    1030    4.70 (43.29)    4.87 (37.15)  4.02 (134.01)   \n",
       "4       wine   11    1599     0.64 (6.01)     0.63 (3.58)              –   \n",
       "5      power    4    9568    3.41 (56.92)    3.46 (28.88)              –   \n",
       "6     kin8nm    8    8192    0.12 (96.50)    0.10 (60.40)              –   \n",
       "7      naval   17   11934   0.00 (107.98)    0.00 (56.19)              –   \n",
       "8    protein    9   45730   1.94 (611.38)    1.94 (96.80)              –   \n",
       "9       blog  280   52397  23.49 (185.49)    23.46 (9.90)              –   \n",
       "10     slice  384   53500  1.23 (3350.61)  1.24 (3067.95)              –   \n",
       "11   yearmsd   90  515345  8.54 (4616.82)  8.54 (1543.05)              –   \n",
       "\n",
       "            LASSO            HAR     KernelHAR  \n",
       "0     8.92 (0.01)    0.42 (0.49)   0.30 (9.80)  \n",
       "1     4.14 (0.01)    0.43 (1.86)  0.39 (30.21)  \n",
       "2     5.02 (0.01)   3.79 (49.22)             –  \n",
       "3    10.40 (0.01)    3.96 (3.69)             –  \n",
       "4     0.67 (0.03)  0.59 (107.46)             –  \n",
       "5     4.59 (0.04)   3.34 (83.11)             –  \n",
       "6     0.21 (0.03)              –             –  \n",
       "7    0.01 (10.51)              –             –  \n",
       "8     2.50 (0.33)              –             –  \n",
       "9   28.25 (13.51)              –             –  \n",
       "10  8.33 (121.71)              –             –  \n",
       "11   9.49 (40.09)              –             –  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>p</th>\n",
       "      <th>n</th>\n",
       "      <th>LTB</th>\n",
       "      <th>GBT</th>\n",
       "      <th>HAL</th>\n",
       "      <th>LASSO</th>\n",
       "      <th>HAR</th>\n",
       "      <th>KernelHAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yacht</td>\n",
       "      <td>6</td>\n",
       "      <td>308</td>\n",
       "      <td>0.90 (10.69)</td>\n",
       "      <td>0.90 (4.68)</td>\n",
       "      <td>0.72 (0.92)</td>\n",
       "      <td>8.92 (0.01)</td>\n",
       "      <td>0.42 (0.49)</td>\n",
       "      <td>0.30 (9.80)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>energy</td>\n",
       "      <td>8</td>\n",
       "      <td>768</td>\n",
       "      <td>0.40 (30.82)</td>\n",
       "      <td>0.40 (21.46)</td>\n",
       "      <td>0.43 (45.80)</td>\n",
       "      <td>4.14 (0.01)</td>\n",
       "      <td>0.43 (1.86)</td>\n",
       "      <td>0.39 (30.21)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boston</td>\n",
       "      <td>13</td>\n",
       "      <td>506</td>\n",
       "      <td>3.35 (5.92)</td>\n",
       "      <td>3.43 (4.47)</td>\n",
       "      <td>3.66 (916.61)</td>\n",
       "      <td>5.02 (0.01)</td>\n",
       "      <td>3.79 (49.22)</td>\n",
       "      <td>3.39 (15.92)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>concrete</td>\n",
       "      <td>8</td>\n",
       "      <td>1030</td>\n",
       "      <td>4.70 (43.29)</td>\n",
       "      <td>4.87 (37.15)</td>\n",
       "      <td>4.02 (134.01)</td>\n",
       "      <td>10.40 (0.01)</td>\n",
       "      <td>3.96 (3.69)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wine</td>\n",
       "      <td>11</td>\n",
       "      <td>1599</td>\n",
       "      <td>0.64 (6.01)</td>\n",
       "      <td>0.63 (3.58)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.67 (0.03)</td>\n",
       "      <td>0.59 (107.46)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>power</td>\n",
       "      <td>4</td>\n",
       "      <td>9568</td>\n",
       "      <td>3.41 (56.92)</td>\n",
       "      <td>3.46 (28.88)</td>\n",
       "      <td>–</td>\n",
       "      <td>4.59 (0.04)</td>\n",
       "      <td>3.34 (83.11)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kin8nm</td>\n",
       "      <td>8</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.12 (96.50)</td>\n",
       "      <td>0.10 (60.40)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.21 (0.03)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>naval</td>\n",
       "      <td>17</td>\n",
       "      <td>11934</td>\n",
       "      <td>0.00 (107.98)</td>\n",
       "      <td>0.00 (56.19)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.01 (10.51)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>protein</td>\n",
       "      <td>9</td>\n",
       "      <td>45730</td>\n",
       "      <td>1.94 (611.38)</td>\n",
       "      <td>1.94 (96.80)</td>\n",
       "      <td>–</td>\n",
       "      <td>2.50 (0.33)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>blog</td>\n",
       "      <td>280</td>\n",
       "      <td>52397</td>\n",
       "      <td>23.49 (185.49)</td>\n",
       "      <td>23.46 (9.90)</td>\n",
       "      <td>–</td>\n",
       "      <td>28.25 (13.51)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>slice</td>\n",
       "      <td>384</td>\n",
       "      <td>53500</td>\n",
       "      <td>1.23 (3350.61)</td>\n",
       "      <td>1.24 (3067.95)</td>\n",
       "      <td>–</td>\n",
       "      <td>8.33 (121.71)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>yearmsd</td>\n",
       "      <td>90</td>\n",
       "      <td>515345</td>\n",
       "      <td>8.54 (4616.82)</td>\n",
       "      <td>8.54 (1543.05)</td>\n",
       "      <td>–</td>\n",
       "      <td>9.49 (40.09)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        data    p       n             LTB             GBT            HAL  \\\n",
       "0      yacht    6     308    0.90 (10.69)     0.90 (4.68)    0.72 (0.92)   \n",
       "1     energy    8     768    0.40 (30.82)    0.40 (21.46)   0.43 (45.80)   \n",
       "2     boston   13     506     3.35 (5.92)     3.43 (4.47)  3.66 (916.61)   \n",
       "3   concrete    8    1030    4.70 (43.29)    4.87 (37.15)  4.02 (134.01)   \n",
       "4       wine   11    1599     0.64 (6.01)     0.63 (3.58)              –   \n",
       "5      power    4    9568    3.41 (56.92)    3.46 (28.88)              –   \n",
       "6     kin8nm    8    8192    0.12 (96.50)    0.10 (60.40)              –   \n",
       "7      naval   17   11934   0.00 (107.98)    0.00 (56.19)              –   \n",
       "8    protein    9   45730   1.94 (611.38)    1.94 (96.80)              –   \n",
       "9       blog  280   52397  23.49 (185.49)    23.46 (9.90)              –   \n",
       "10     slice  384   53500  1.23 (3350.61)  1.24 (3067.95)              –   \n",
       "11   yearmsd   90  515345  8.54 (4616.82)  8.54 (1543.05)              –   \n",
       "\n",
       "            LASSO            HAR     KernelHAR  \n",
       "0     8.92 (0.01)    0.42 (0.49)   0.30 (9.80)  \n",
       "1     4.14 (0.01)    0.43 (1.86)  0.39 (30.21)  \n",
       "2     5.02 (0.01)   3.79 (49.22)  3.39 (15.92)  \n",
       "3    10.40 (0.01)    3.96 (3.69)             –  \n",
       "4     0.67 (0.03)  0.59 (107.46)             –  \n",
       "5     4.59 (0.04)   3.34 (83.11)             –  \n",
       "6     0.21 (0.03)              –             –  \n",
       "7    0.01 (10.51)              –             –  \n",
       "8     2.50 (0.33)              –             –  \n",
       "9   28.25 (13.51)              –             –  \n",
       "10  8.33 (121.71)              –             –  \n",
       "11   9.49 (40.09)              –             –  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>p</th>\n",
       "      <th>n</th>\n",
       "      <th>LTB</th>\n",
       "      <th>GBT</th>\n",
       "      <th>HAL</th>\n",
       "      <th>LASSO</th>\n",
       "      <th>HAR</th>\n",
       "      <th>KernelHAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yacht</td>\n",
       "      <td>6</td>\n",
       "      <td>308</td>\n",
       "      <td>0.90 (10.69)</td>\n",
       "      <td>0.90 (4.68)</td>\n",
       "      <td>0.72 (0.92)</td>\n",
       "      <td>8.92 (0.01)</td>\n",
       "      <td>0.42 (0.49)</td>\n",
       "      <td>0.30 (9.80)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>energy</td>\n",
       "      <td>8</td>\n",
       "      <td>768</td>\n",
       "      <td>0.40 (30.82)</td>\n",
       "      <td>0.40 (21.46)</td>\n",
       "      <td>0.43 (45.80)</td>\n",
       "      <td>4.14 (0.01)</td>\n",
       "      <td>0.43 (1.86)</td>\n",
       "      <td>0.39 (30.21)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boston</td>\n",
       "      <td>13</td>\n",
       "      <td>506</td>\n",
       "      <td>3.35 (5.92)</td>\n",
       "      <td>3.43 (4.47)</td>\n",
       "      <td>3.66 (916.61)</td>\n",
       "      <td>5.02 (0.01)</td>\n",
       "      <td>3.79 (49.22)</td>\n",
       "      <td>3.39 (15.92)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>concrete</td>\n",
       "      <td>8</td>\n",
       "      <td>1030</td>\n",
       "      <td>4.70 (43.29)</td>\n",
       "      <td>4.87 (37.15)</td>\n",
       "      <td>4.02 (134.01)</td>\n",
       "      <td>10.40 (0.01)</td>\n",
       "      <td>3.96 (3.69)</td>\n",
       "      <td>3.88 (70.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wine</td>\n",
       "      <td>11</td>\n",
       "      <td>1599</td>\n",
       "      <td>0.64 (6.01)</td>\n",
       "      <td>0.63 (3.58)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.67 (0.03)</td>\n",
       "      <td>0.59 (107.46)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>power</td>\n",
       "      <td>4</td>\n",
       "      <td>9568</td>\n",
       "      <td>3.41 (56.92)</td>\n",
       "      <td>3.46 (28.88)</td>\n",
       "      <td>–</td>\n",
       "      <td>4.59 (0.04)</td>\n",
       "      <td>3.34 (83.11)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kin8nm</td>\n",
       "      <td>8</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.12 (96.50)</td>\n",
       "      <td>0.10 (60.40)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.21 (0.03)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>naval</td>\n",
       "      <td>17</td>\n",
       "      <td>11934</td>\n",
       "      <td>0.00 (107.98)</td>\n",
       "      <td>0.00 (56.19)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.01 (10.51)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>protein</td>\n",
       "      <td>9</td>\n",
       "      <td>45730</td>\n",
       "      <td>1.94 (611.38)</td>\n",
       "      <td>1.94 (96.80)</td>\n",
       "      <td>–</td>\n",
       "      <td>2.50 (0.33)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>blog</td>\n",
       "      <td>280</td>\n",
       "      <td>52397</td>\n",
       "      <td>23.49 (185.49)</td>\n",
       "      <td>23.46 (9.90)</td>\n",
       "      <td>–</td>\n",
       "      <td>28.25 (13.51)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>slice</td>\n",
       "      <td>384</td>\n",
       "      <td>53500</td>\n",
       "      <td>1.23 (3350.61)</td>\n",
       "      <td>1.24 (3067.95)</td>\n",
       "      <td>–</td>\n",
       "      <td>8.33 (121.71)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>yearmsd</td>\n",
       "      <td>90</td>\n",
       "      <td>515345</td>\n",
       "      <td>8.54 (4616.82)</td>\n",
       "      <td>8.54 (1543.05)</td>\n",
       "      <td>–</td>\n",
       "      <td>9.49 (40.09)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        data    p       n             LTB             GBT            HAL  \\\n",
       "0      yacht    6     308    0.90 (10.69)     0.90 (4.68)    0.72 (0.92)   \n",
       "1     energy    8     768    0.40 (30.82)    0.40 (21.46)   0.43 (45.80)   \n",
       "2     boston   13     506     3.35 (5.92)     3.43 (4.47)  3.66 (916.61)   \n",
       "3   concrete    8    1030    4.70 (43.29)    4.87 (37.15)  4.02 (134.01)   \n",
       "4       wine   11    1599     0.64 (6.01)     0.63 (3.58)              –   \n",
       "5      power    4    9568    3.41 (56.92)    3.46 (28.88)              –   \n",
       "6     kin8nm    8    8192    0.12 (96.50)    0.10 (60.40)              –   \n",
       "7      naval   17   11934   0.00 (107.98)    0.00 (56.19)              –   \n",
       "8    protein    9   45730   1.94 (611.38)    1.94 (96.80)              –   \n",
       "9       blog  280   52397  23.49 (185.49)    23.46 (9.90)              –   \n",
       "10     slice  384   53500  1.23 (3350.61)  1.24 (3067.95)              –   \n",
       "11   yearmsd   90  515345  8.54 (4616.82)  8.54 (1543.05)              –   \n",
       "\n",
       "            LASSO            HAR     KernelHAR  \n",
       "0     8.92 (0.01)    0.42 (0.49)   0.30 (9.80)  \n",
       "1     4.14 (0.01)    0.43 (1.86)  0.39 (30.21)  \n",
       "2     5.02 (0.01)   3.79 (49.22)  3.39 (15.92)  \n",
       "3    10.40 (0.01)    3.96 (3.69)  3.88 (70.02)  \n",
       "4     0.67 (0.03)  0.59 (107.46)             –  \n",
       "5     4.59 (0.04)   3.34 (83.11)             –  \n",
       "6     0.21 (0.03)              –             –  \n",
       "7    0.01 (10.51)              –             –  \n",
       "8     2.50 (0.33)              –             –  \n",
       "9   28.25 (13.51)              –             –  \n",
       "10  8.33 (121.71)              –             –  \n",
       "11   9.49 (40.09)              –             –  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>p</th>\n",
       "      <th>n</th>\n",
       "      <th>LTB</th>\n",
       "      <th>GBT</th>\n",
       "      <th>HAL</th>\n",
       "      <th>LASSO</th>\n",
       "      <th>HAR</th>\n",
       "      <th>KernelHAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yacht</td>\n",
       "      <td>6</td>\n",
       "      <td>308</td>\n",
       "      <td>0.90 (10.69)</td>\n",
       "      <td>0.90 (4.68)</td>\n",
       "      <td>0.72 (0.92)</td>\n",
       "      <td>8.92 (0.01)</td>\n",
       "      <td>0.42 (0.49)</td>\n",
       "      <td>0.30 (9.80)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>energy</td>\n",
       "      <td>8</td>\n",
       "      <td>768</td>\n",
       "      <td>0.40 (30.82)</td>\n",
       "      <td>0.40 (21.46)</td>\n",
       "      <td>0.43 (45.80)</td>\n",
       "      <td>4.14 (0.01)</td>\n",
       "      <td>0.43 (1.86)</td>\n",
       "      <td>0.39 (30.21)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boston</td>\n",
       "      <td>13</td>\n",
       "      <td>506</td>\n",
       "      <td>3.35 (5.92)</td>\n",
       "      <td>3.43 (4.47)</td>\n",
       "      <td>3.66 (916.61)</td>\n",
       "      <td>5.02 (0.01)</td>\n",
       "      <td>3.79 (49.22)</td>\n",
       "      <td>3.39 (15.92)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>concrete</td>\n",
       "      <td>8</td>\n",
       "      <td>1030</td>\n",
       "      <td>4.70 (43.29)</td>\n",
       "      <td>4.87 (37.15)</td>\n",
       "      <td>4.02 (134.01)</td>\n",
       "      <td>10.40 (0.01)</td>\n",
       "      <td>3.96 (3.69)</td>\n",
       "      <td>3.88 (70.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wine</td>\n",
       "      <td>11</td>\n",
       "      <td>1599</td>\n",
       "      <td>0.64 (6.01)</td>\n",
       "      <td>0.63 (3.58)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.67 (0.03)</td>\n",
       "      <td>0.59 (107.46)</td>\n",
       "      <td>0.60 (520.56)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>power</td>\n",
       "      <td>4</td>\n",
       "      <td>9568</td>\n",
       "      <td>3.41 (56.92)</td>\n",
       "      <td>3.46 (28.88)</td>\n",
       "      <td>–</td>\n",
       "      <td>4.59 (0.04)</td>\n",
       "      <td>3.34 (83.11)</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kin8nm</td>\n",
       "      <td>8</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.12 (96.50)</td>\n",
       "      <td>0.10 (60.40)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.21 (0.03)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>naval</td>\n",
       "      <td>17</td>\n",
       "      <td>11934</td>\n",
       "      <td>0.00 (107.98)</td>\n",
       "      <td>0.00 (56.19)</td>\n",
       "      <td>–</td>\n",
       "      <td>0.01 (10.51)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>protein</td>\n",
       "      <td>9</td>\n",
       "      <td>45730</td>\n",
       "      <td>1.94 (611.38)</td>\n",
       "      <td>1.94 (96.80)</td>\n",
       "      <td>–</td>\n",
       "      <td>2.50 (0.33)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>blog</td>\n",
       "      <td>280</td>\n",
       "      <td>52397</td>\n",
       "      <td>23.49 (185.49)</td>\n",
       "      <td>23.46 (9.90)</td>\n",
       "      <td>–</td>\n",
       "      <td>28.25 (13.51)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>slice</td>\n",
       "      <td>384</td>\n",
       "      <td>53500</td>\n",
       "      <td>1.23 (3350.61)</td>\n",
       "      <td>1.24 (3067.95)</td>\n",
       "      <td>–</td>\n",
       "      <td>8.33 (121.71)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>yearmsd</td>\n",
       "      <td>90</td>\n",
       "      <td>515345</td>\n",
       "      <td>8.54 (4616.82)</td>\n",
       "      <td>8.54 (1543.05)</td>\n",
       "      <td>–</td>\n",
       "      <td>9.49 (40.09)</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        data    p       n             LTB             GBT            HAL  \\\n",
       "0      yacht    6     308    0.90 (10.69)     0.90 (4.68)    0.72 (0.92)   \n",
       "1     energy    8     768    0.40 (30.82)    0.40 (21.46)   0.43 (45.80)   \n",
       "2     boston   13     506     3.35 (5.92)     3.43 (4.47)  3.66 (916.61)   \n",
       "3   concrete    8    1030    4.70 (43.29)    4.87 (37.15)  4.02 (134.01)   \n",
       "4       wine   11    1599     0.64 (6.01)     0.63 (3.58)              –   \n",
       "5      power    4    9568    3.41 (56.92)    3.46 (28.88)              –   \n",
       "6     kin8nm    8    8192    0.12 (96.50)    0.10 (60.40)              –   \n",
       "7      naval   17   11934   0.00 (107.98)    0.00 (56.19)              –   \n",
       "8    protein    9   45730   1.94 (611.38)    1.94 (96.80)              –   \n",
       "9       blog  280   52397  23.49 (185.49)    23.46 (9.90)              –   \n",
       "10     slice  384   53500  1.23 (3350.61)  1.24 (3067.95)              –   \n",
       "11   yearmsd   90  515345  8.54 (4616.82)  8.54 (1543.05)              –   \n",
       "\n",
       "            LASSO            HAR      KernelHAR  \n",
       "0     8.92 (0.01)    0.42 (0.49)    0.30 (9.80)  \n",
       "1     4.14 (0.01)    0.43 (1.86)   0.39 (30.21)  \n",
       "2     5.02 (0.01)   3.79 (49.22)   3.39 (15.92)  \n",
       "3    10.40 (0.01)    3.96 (3.69)   3.88 (70.02)  \n",
       "4     0.67 (0.03)  0.59 (107.46)  0.60 (520.56)  \n",
       "5     4.59 (0.04)   3.34 (83.11)              –  \n",
       "6     0.21 (0.03)              –              –  \n",
       "7    0.01 (10.51)              –              –  \n",
       "8     2.50 (0.33)              –              –  \n",
       "9   28.25 (13.51)              –              –  \n",
       "10  8.33 (121.71)              –              –  \n",
       "11   9.49 (40.09)              –              –  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from kernel_har import KernelHAR\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import time\n",
    "import multiprocessing\n",
    "import os\n",
    "\n",
    "table_file_name = \"models_compare_table.pickle\"\n",
    "table_df = pd.read_pickle(table_file_name)\n",
    "\n",
    "for dataset_name in table_df['data']:\n",
    "    method = KernelHAR()\n",
    "    rmse, training_time = run_real_data_trials(dataset_name, method)\n",
    "    update_results(table_df, dataset_name, method.name, rmse, training_time)\n",
    "\n",
    "    # Save the updated DataFrame\n",
    "    table_df.to_pickle(table_file_name)\n",
    "\n",
    "    # Display the updated DataFrame\n",
    "    display(table_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Highly_Adaptive_Ridge-awx9OXbz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
